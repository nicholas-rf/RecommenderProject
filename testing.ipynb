{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/miniforge3/envs/recSysEnv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertModel\n",
    "import keras.api._v2.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We now want to move on to creating a matrix of users and rated items for the classical methods such as SVD, ALS OLS and others\n",
    "## Creating a matrix means having articles and users, and to avoid size issues I can just implement a method that allows a dimnension to be specified \n",
    "## It does seem however that the matrix expectation is that of a 2d numpy array instead of a dataframe? Will have to check the lecture stuff\n",
    "## I mean how hard could it be with a dataframe? Now that I try to work on it, its giving tomorrows issue hahaha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How can I apply the embeddings? load and then return the dataframe mythink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_embeddings(dataset):\n",
    "    \"\"\"\n",
    "    Applies pre-trained BERT embeddings to the feature columns with text data for use within clustering.\n",
    "\n",
    "    Args:\n",
    "        dataset (pd.DataFrame) : Dataset containing user interactions.\n",
    "\n",
    "    Returns:\n",
    "        dataset (pd.DataFrame) : A dataset with embeddings columns.\n",
    "    \"\"\"\n",
    "    # Initialize the bert tokenizer and model from bert base cased.\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "    model = TFBertModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "    # Create a dense layer with the embedding dimension to process embeddings.\n",
    "    embedding_dimension = 8\n",
    "    dense_layer = keras.layers.Dense(embedding_dimension, activation='linear')\n",
    "\n",
    "    # Define a function to get the embeddings from the models and apply them to the text.\n",
    "    def get_embeddings(text_1):\n",
    "        \"\"\"\n",
    "        Gets embeddings from pre trained bert model for news information used for clustering.\n",
    "        \"\"\"\n",
    "\n",
    "        # Apply the tokenizer to the text and return it in the tensorflow tensor format. \n",
    "        encoded_text = tokenizer(text_1, return_tensors='tf')\n",
    "\n",
    "        # Get the output from BERT model with the encoded text.\n",
    "        bert_output = model(encoded_text)\n",
    "\n",
    "        # Use the pooled output for a single vector representation of the input. \n",
    "        pooled_output = bert_output.pooler_output\n",
    "\n",
    "        # Apply dense layer to project to desired size.\n",
    "        embedding_vector = list(dense_layer(pooled_output).numpy())\n",
    "        return embedding_vector\n",
    "\n",
    "    # Apply the embeddings to the abstract and title columns.\n",
    "    dataset['abstract_embeddings'] = dataset['abstract'].apply(get_embeddings)\n",
    "    dataset['title_embeddings'] = dataset['title'].apply(get_embeddings)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ExploratoryAnalysis.data_processing_modules as dpm\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras.api._v2.keras as keras\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = pd.read_csv('MIND_small/sample_tf_dataset.csv')\n",
    "sample_data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "sample_data = sample_data[sample_data['abstract'].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = sample_data.loc[1:10, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "/var/folders/83/h9nx83394pb5k_0h4zbb4lw00000gn/T/ipykernel_74193/2591313069.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['abstract_embeddings'] = dataset['abstract'].apply(get_embeddings)\n",
      "/var/folders/83/h9nx83394pb5k_0h4zbb4lw00000gn/T/ipykernel_74193/2591313069.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['title_embeddings'] = dataset['title'].apply(get_embeddings)\n"
     ]
    }
   ],
   "source": [
    "data = create_text_embeddings(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time_</th>\n",
       "      <th>news_id</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>interaction_type</th>\n",
       "      <th>score</th>\n",
       "      <th>abstract_embeddings</th>\n",
       "      <th>title_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N42782</td>\n",
       "      <td>sports</td>\n",
       "      <td>baseball_mlb</td>\n",
       "      <td>Three takeaways from Yankees' ALCS Game 5 vict...</td>\n",
       "      <td>The Yankees kept hope alive thanks to some imp...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "      <td>[[1.5487633, 1.0190098, -1.1760546, -1.7435807...</td>\n",
       "      <td>[[1.2311747, 1.1580857, -1.0968894, -1.6441334...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N34694</td>\n",
       "      <td>tv</td>\n",
       "      <td>tvnews</td>\n",
       "      <td>Rosie O'Donnell: Barbara Walters Isn't 'Up to ...</td>\n",
       "      <td>Rosie O'Donnell: Barbara Walters Isn't 'Up to ...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "      <td>[[1.3630767, 1.3074028, -1.0594987, -1.8798711...</td>\n",
       "      <td>[[1.3630767, 1.3074028, -1.0594987, -1.8798711...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N45794</td>\n",
       "      <td>news</td>\n",
       "      <td>newscrime</td>\n",
       "      <td>Four flight attendants were arrested in Miami'...</td>\n",
       "      <td>Four American Airlines flight attendants were ...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "      <td>[[1.3427523, 0.9994156, -1.1305358, -1.492023,...</td>\n",
       "      <td>[[1.2866648, 1.0701438, -1.1815537, -1.5371481...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N18445</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_ncaa</td>\n",
       "      <td>Michigan sends breakup tweet to Notre Dame as ...</td>\n",
       "      <td>Parting is such sweet sorrow, say the Wolverines.</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "      <td>[[1.470107, 1.2682941, -1.3315637, -1.9740347,...</td>\n",
       "      <td>[[1.3234937, 1.0959133, -1.2446544, -1.8129985...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N63302</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestylebuzz</td>\n",
       "      <td>This Wedding Photo of a Canine Best Man Captur...</td>\n",
       "      <td>When Mark Doublet made his dog, Marley, the be...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "      <td>[[1.3351053, 0.99234486, -1.1616077, -1.547308...</td>\n",
       "      <td>[[1.4223776, 1.3358438, -1.0546858, -1.7920129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N10414</td>\n",
       "      <td>movies</td>\n",
       "      <td>movienews</td>\n",
       "      <td>Robert Evans, 'Chinatown' Producer and Paramou...</td>\n",
       "      <td>Robert Evans, the Paramount executive who prod...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "      <td>[[1.4915154, 1.0339155, -0.8287275, -1.2396467...</td>\n",
       "      <td>[[1.354709, 1.1848016, -1.0151962, -1.7490983,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N19347</td>\n",
       "      <td>news</td>\n",
       "      <td>newspolitics</td>\n",
       "      <td>Former US Senator Kay Hagan dead at 66</td>\n",
       "      <td>Former U.S. Sen. Kay Hagan, a one-time Capitol...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "      <td>[[1.3786186, 1.0445164, -1.0278101, -1.4561397...</td>\n",
       "      <td>[[1.1155573, 1.2894244, -1.0174193, -1.6100097...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N31801</td>\n",
       "      <td>news</td>\n",
       "      <td>newspolitics</td>\n",
       "      <td>Joe Biden reportedly denied Communion at a Sou...</td>\n",
       "      <td>Joe Biden has a complicated history with the C...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "      <td>[[1.4460843, 0.95543987, -1.1360129, -1.306054...</td>\n",
       "      <td>[[1.2764208, 1.257126, -0.7476753, -0.9903929,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N55689</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_nfl</td>\n",
       "      <td>Charles Rogers, former Michigan State football...</td>\n",
       "      <td>Charles Rogers, the former Michigan State foot...</td>\n",
       "      <td>impression</td>\n",
       "      <td>0</td>\n",
       "      <td>[[1.3354195, 1.12606, -1.1411066, -1.5229899, ...</td>\n",
       "      <td>[[1.3344136, 1.2568424, -1.0704972, -1.4981291...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N35729</td>\n",
       "      <td>news</td>\n",
       "      <td>newsus</td>\n",
       "      <td>Porsche launches into second story of New Jers...</td>\n",
       "      <td>The Porsche went airborne off a median in Toms...</td>\n",
       "      <td>impression</td>\n",
       "      <td>0</td>\n",
       "      <td>[[1.3749304, 0.92098105, -0.98385656, -1.32200...</td>\n",
       "      <td>[[1.2780826, 0.92301315, -1.0932304, -1.584886...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                  time_ news_id   category   sub_category  \\\n",
       "1   U13740  11/11/2019 9:05:58 AM  N42782     sports   baseball_mlb   \n",
       "2   U13740  11/11/2019 9:05:58 AM  N34694         tv         tvnews   \n",
       "3   U13740  11/11/2019 9:05:58 AM  N45794       news      newscrime   \n",
       "4   U13740  11/11/2019 9:05:58 AM  N18445     sports  football_ncaa   \n",
       "5   U13740  11/11/2019 9:05:58 AM  N63302  lifestyle  lifestylebuzz   \n",
       "6   U13740  11/11/2019 9:05:58 AM  N10414     movies      movienews   \n",
       "7   U13740  11/11/2019 9:05:58 AM  N19347       news   newspolitics   \n",
       "8   U13740  11/11/2019 9:05:58 AM  N31801       news   newspolitics   \n",
       "9   U13740  11/11/2019 9:05:58 AM  N55689     sports   football_nfl   \n",
       "10  U13740  11/11/2019 9:05:58 AM  N35729       news         newsus   \n",
       "\n",
       "                                                title  \\\n",
       "1   Three takeaways from Yankees' ALCS Game 5 vict...   \n",
       "2   Rosie O'Donnell: Barbara Walters Isn't 'Up to ...   \n",
       "3   Four flight attendants were arrested in Miami'...   \n",
       "4   Michigan sends breakup tweet to Notre Dame as ...   \n",
       "5   This Wedding Photo of a Canine Best Man Captur...   \n",
       "6   Robert Evans, 'Chinatown' Producer and Paramou...   \n",
       "7              Former US Senator Kay Hagan dead at 66   \n",
       "8   Joe Biden reportedly denied Communion at a Sou...   \n",
       "9   Charles Rogers, former Michigan State football...   \n",
       "10  Porsche launches into second story of New Jers...   \n",
       "\n",
       "                                             abstract interaction_type  score  \\\n",
       "1   The Yankees kept hope alive thanks to some imp...          history      1   \n",
       "2   Rosie O'Donnell: Barbara Walters Isn't 'Up to ...          history      1   \n",
       "3   Four American Airlines flight attendants were ...          history      1   \n",
       "4   Parting is such sweet sorrow, say the Wolverines.          history      1   \n",
       "5   When Mark Doublet made his dog, Marley, the be...          history      1   \n",
       "6   Robert Evans, the Paramount executive who prod...          history      1   \n",
       "7   Former U.S. Sen. Kay Hagan, a one-time Capitol...          history      1   \n",
       "8   Joe Biden has a complicated history with the C...          history      1   \n",
       "9   Charles Rogers, the former Michigan State foot...       impression      0   \n",
       "10  The Porsche went airborne off a median in Toms...       impression      0   \n",
       "\n",
       "                                  abstract_embeddings  \\\n",
       "1   [[1.5487633, 1.0190098, -1.1760546, -1.7435807...   \n",
       "2   [[1.3630767, 1.3074028, -1.0594987, -1.8798711...   \n",
       "3   [[1.3427523, 0.9994156, -1.1305358, -1.492023,...   \n",
       "4   [[1.470107, 1.2682941, -1.3315637, -1.9740347,...   \n",
       "5   [[1.3351053, 0.99234486, -1.1616077, -1.547308...   \n",
       "6   [[1.4915154, 1.0339155, -0.8287275, -1.2396467...   \n",
       "7   [[1.3786186, 1.0445164, -1.0278101, -1.4561397...   \n",
       "8   [[1.4460843, 0.95543987, -1.1360129, -1.306054...   \n",
       "9   [[1.3354195, 1.12606, -1.1411066, -1.5229899, ...   \n",
       "10  [[1.3749304, 0.92098105, -0.98385656, -1.32200...   \n",
       "\n",
       "                                     title_embeddings  \n",
       "1   [[1.2311747, 1.1580857, -1.0968894, -1.6441334...  \n",
       "2   [[1.3630767, 1.3074028, -1.0594987, -1.8798711...  \n",
       "3   [[1.2866648, 1.0701438, -1.1815537, -1.5371481...  \n",
       "4   [[1.3234937, 1.0959133, -1.2446544, -1.8129985...  \n",
       "5   [[1.4223776, 1.3358438, -1.0546858, -1.7920129...  \n",
       "6   [[1.354709, 1.1848016, -1.0151962, -1.7490983,...  \n",
       "7   [[1.1155573, 1.2894244, -1.0174193, -1.6100097...  \n",
       "8   [[1.2764208, 1.257126, -0.7476753, -0.9903929,...  \n",
       "9   [[1.3344136, 1.2568424, -1.0704972, -1.4981291...  \n",
       "10  [[1.2780826, 0.92301315, -1.0932304, -1.584886...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                object\n",
       "time_                  object\n",
       "news_id                object\n",
       "category               object\n",
       "sub_category           object\n",
       "title                  object\n",
       "abstract               object\n",
       "interaction_type       object\n",
       "score                   int64\n",
       "abstract_embeddings    object\n",
       "title_embeddings       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting off we need to load in the dataset and turn it into the form we want\n",
    "sample_data = pd.read_csv('MIND_small/sample_tf_dataset.csv')\n",
    "sample_data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "sample_data = sample_data[sample_data['abstract'].isna() == False]\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "tf_data_obj = tf.data.Dataset.from_tensor_slices(dict(sample_data))\n",
    "train_ds = tf_data_obj.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "text_ds = train_ds.map(lambda x: x['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we need to create a text vectorization layer to handle preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame.rename(columns={'time':'time_'}, inplace=True)\n",
    "test_frame.to_csv('MIND_small/sample_tf_dataset.csv')\n",
    "\n",
    "def create_connection():\n",
    "    \"\"\"\n",
    "    Creates a connection to the database by taking in a user password.\n",
    "    \"\"\"\n",
    "    database_name = 'user_info'\n",
    "    connection_user = 'admin'\n",
    "    try:\n",
    "        connection_password = input(\"Enter Password: \")\n",
    "        connection_host = 'svc-57117697-8d22-448b-8b96-d3b2a46d0970-dml.aws-virginia-6.svc.singlestore.com'\n",
    "        connection_port = '3306'\n",
    "        connection_url = f\"mysql+pymysql://{connection_user}:{connection_password}@{connection_host}:{connection_port}/{database_name}\"\n",
    "        db_connection = create_engine(connection_url)\n",
    "        return db_connection\n",
    "    except Exception as e:\n",
    "        print(f\"Exception {e} occured, try again.\\n\")\n",
    "        return create_connection()\n",
    "\n",
    "\n",
    "def push_to_DB(news : pd.DataFrame, behaviors : pd.DataFrame) -> None:\n",
    "    \"\"\" \n",
    "    Pushes data to the SingleStore database for usage in modelling within docker containers and virtual machines.\n",
    "\n",
    "    Args:\n",
    "        news (pd.DataFrame) : The dataframe containing the data from the news csv.\n",
    "        behaviors (pd.DataFrame) : The dataframe containing the data from the behaviors csv.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    db_connection = create_connection()\n",
    "    user_interaction_data = dpm.decompose_interactions(num_iterations=100000, news=news, behaviors=behaviors)\n",
    "    user_interaction_data.to_sql('user_behaviors', if_exists='replace', con=db_connection, index=False)\n",
    "    print(\"Push to Database Successful\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recSysEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
