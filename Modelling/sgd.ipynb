{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matrix_modules\n",
    "import sys\n",
    "sys.path.append('/home/jovyan/work')\n",
    "import ExploratoryAnalysis.clustering_modules as cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>248963</th>\n",
       "      <th>248964</th>\n",
       "      <th>248965</th>\n",
       "      <th>248966</th>\n",
       "      <th>248967</th>\n",
       "      <th>248968</th>\n",
       "      <th>248969</th>\n",
       "      <th>248970</th>\n",
       "      <th>248971</th>\n",
       "      <th>248972</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>finance</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tv</th>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.045977</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>music</th>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strength</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newslocalpolitics</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>games-news</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_time</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>37.000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>13.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 255990 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0          1          2          3          4       \\\n",
       "finance             0.111111   0.046512   0.000000   0.137931   0.043011   \n",
       "video               0.083333   0.046512   0.000000   0.034483   0.010753   \n",
       "tv                  0.097222   0.023256   0.111111   0.045977   0.032258   \n",
       "movies              0.013889   0.000000   0.111111   0.022989   0.043011   \n",
       "music               0.013889   0.046512   0.000000   0.022989   0.000000   \n",
       "...                      ...        ...        ...        ...        ...   \n",
       "strength            0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "newslocalpolitics   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "games-news          0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "median_time         0.375000   0.250000   0.375000   0.291667   0.500000   \n",
       "cluster            37.000000  43.000000  37.000000  16.000000  35.000000   \n",
       "\n",
       "                   5          6          7         8          9       ...  \\\n",
       "finance             0.000   0.111111   0.166667  0.166667   0.000000  ...   \n",
       "video               0.000   0.037037   0.083333  0.000000   0.041667  ...   \n",
       "tv                  0.100   0.111111   0.000000  0.083333   0.041667  ...   \n",
       "movies              0.050   0.037037   0.000000  0.083333   0.000000  ...   \n",
       "music               0.000   0.000000   0.000000  0.083333   0.000000  ...   \n",
       "...                   ...        ...        ...       ...        ...  ...   \n",
       "strength            0.000   0.000000   0.000000  0.000000   0.000000  ...   \n",
       "newslocalpolitics   0.000   0.000000   0.000000  0.000000   0.000000  ...   \n",
       "games-news          0.000   0.000000   0.000000  0.000000   0.000000  ...   \n",
       "median_time         0.375   0.208333   0.375000  0.416667   0.291667  ...   \n",
       "cluster            37.000  43.000000  37.000000  7.000000  15.000000  ...   \n",
       "\n",
       "                     248963     248964     248965    248966     248967  \\\n",
       "finance            0.076923   0.000000   0.033333  0.000000   0.117647   \n",
       "video              0.000000   0.000000   0.000000  0.035714   0.000000   \n",
       "tv                 0.153846   0.300000   0.100000  0.178571   0.176471   \n",
       "movies             0.000000   0.100000   0.000000  0.059524   0.000000   \n",
       "music              0.076923   0.000000   0.066667  0.023810   0.000000   \n",
       "...                     ...        ...        ...       ...        ...   \n",
       "strength           0.000000   0.000000   0.000000  0.000000   0.000000   \n",
       "newslocalpolitics  0.000000   0.000000   0.000000  0.000000   0.000000   \n",
       "games-news         0.000000   0.000000   0.000000  0.000000   0.000000   \n",
       "median_time        0.458333   0.416667   0.708333  0.625000   0.500000   \n",
       "cluster            4.000000  18.000000  13.000000  7.000000  37.000000   \n",
       "\n",
       "                     248968     248969     248970     248971  248972  \n",
       "finance            0.000000   0.133333   0.076923   0.111111   0.000  \n",
       "video              0.000000   0.000000   0.000000   0.000000   0.100  \n",
       "tv                 0.000000   0.000000   0.000000   0.000000   0.100  \n",
       "movies             0.000000   0.133333   0.076923   0.000000   0.000  \n",
       "music              0.500000   0.000000   0.038462   0.000000   0.000  \n",
       "...                     ...        ...        ...        ...     ...  \n",
       "strength           0.000000   0.000000   0.000000   0.000000   0.000  \n",
       "newslocalpolitics  0.000000   0.000000   0.000000   0.000000   0.000  \n",
       "games-news         0.000000   0.000000   0.000000   0.000000   0.000  \n",
       "median_time        0.458333   0.333333   0.416667   0.333333   0.375  \n",
       "cluster            0.000000  37.000000  43.000000  32.000000  13.000  \n",
       "\n",
       "[268 rows x 255990 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.iloc[:, 3:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in data\n",
      "Starting Training Loop\n",
      "Unpacking info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting ALS iterations: 100%|██████████| 10/10 [01:11<00:00,  7.20s/it]\n",
      "Starting ALS iterations: 100%|██████████| 100/100 [12:16<00:00,  7.37s/it]\n",
      "Starting ALS iterations:   1%|          | 8/1000 [01:01<2:06:14,  7.64s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 70\u001b[0m\n\u001b[1;32m     62\u001b[0m V \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39mK\u001b[38;5;241m*\u001b[39mM)\u001b[38;5;241m.\u001b[39mreshape((K, M))\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# if j == 0:\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m#     if clustering == \"item\": \u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m#         item_features = item_features.groupby('cluster').agg(sum)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m#         U = np.concatenate((U, user_features.iloc[:, 3:].T), axis=0)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m#         V = np.concatenate((V, item_features.iloc[:, 3:].T), axis=0)\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m U, V, track_error, track_update \u001b[38;5;241m=\u001b[39m \u001b[43mmatrix_modules\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malternating_least_squares\u001b[49m\u001b[43m(\u001b[49m\u001b[43mU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_reg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_reg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m param_info \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclustering_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: clustering, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malg\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m : k, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlambda_reg\u001b[39m\u001b[38;5;124m\"\u001b[39m : lambda_reg, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m : [track_error], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax Updates\u001b[39m\u001b[38;5;124m'\u001b[39m : [track_update]}, index\u001b[38;5;241m=\u001b[39m[counter])\n\u001b[1;32m     72\u001b[0m counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/work/Modelling/matrix_modules.py:290\u001b[0m, in \u001b[0;36malternating_least_squares\u001b[0;34m(U, V, R, user_map, item_map, max_iterations, lambda_reg, diff_threshold)\u001b[0m\n\u001b[1;32m    287\u001b[0m     rated_items \u001b[38;5;241m=\u001b[39m V[:, user_map[i]]\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;66;03m# Update the ith vector of U\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m     U[:, i] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrated_items\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrated_items\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk_In\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m@\u001b[39m (ratings_row \u001b[38;5;241m@\u001b[39m rated_items\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# Fix U and optimize V\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(v_cols), total\u001b[38;5;241m=\u001b[39mv_cols, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOptimizing V\u001b[39m\u001b[38;5;124m'\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;66;03m# Get the ratings for the item \u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/numpy/linalg/linalg.py:488\u001b[0m, in \u001b[0;36m_unary_dispatcher\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ia\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39minvshape)\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# Matrix inversion\u001b[39;00m\n\u001b[0;32m--> 488\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unary_dispatcher\u001b[39m(a):\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a,)\n\u001b[1;32m    492\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_unary_dispatcher)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minv\u001b[39m(a):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matrix_modules \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import sys\n",
    "sys.path.append('/home/jovyan/work/')\n",
    "import ExploratoryAnalysis.clustering_modules as cm\n",
    "\n",
    "\"\"\"\n",
    "This script runs stochastic gradient descent, alternating least squares and factorization machines\n",
    "with several different parameters to determine their affects on performance.\n",
    "\"\"\"\n",
    "\n",
    "## Loading data and getting things ready\n",
    "\n",
    "# Load in the full ratings data with news and users.\n",
    "print(\"Loading in data\")\n",
    "full_ratings, news, users = matrix_modules.load_dataset_for_matrix()\n",
    "\n",
    "\n",
    "# Create a ratings matrix R, and item and user index hash maps for easy subsetting.\n",
    "als_items = [matrix_modules.create_item_cluster_mat(full_ratings, news, isALS=True, num_users=len(users), num_clusters=len(news['cluster'].unique())),\n",
    "         matrix_modules.create_user_cluster_mat(full_ratings, news, users, isALS=True, num_user_clusters=len(users['cluster'].unique()))]\n",
    "\n",
    "\n",
    "# items is now of the form [(R, user_idx, item_idx)]\n",
    "counter = 0\n",
    "results = pd.DataFrame()\n",
    "print(\"Starting Training Loop\")\n",
    "for i in range(2):\n",
    "\n",
    "    if i == 0:\n",
    "        clustering = \"item\"\n",
    "        cluster_type = False\n",
    "    else:\n",
    "        clustering = \"user\"\n",
    "        cluster_type = True\n",
    "\n",
    "    print(\"Unpacking info\")\n",
    "    R, item_idx, user_idx = als_items[i]\n",
    "\n",
    "    # Make the indices into lists and sort them.\n",
    "    item_idx = {num : sorted(list(users)) for num, users in item_idx.items()}\n",
    "    user_idx = {user_id : sorted(list(ratings)) for user_id, ratings in user_idx.items()}\n",
    "\n",
    "    # Create feature matrices for testing.\n",
    "    user_features = pd.read_csv(\"../MIND_large/csv/user_features.csv\", index_col=0)\n",
    "    item_features = pd.read_csv(\"../MIND_large/csv/item_features.csv\", index_col=0)\n",
    "    for j in range(2):\n",
    "        for k in range(5, 55, 5):\n",
    "\n",
    "            for lambda_reg in [0.01, 0.10, 1, 2]:\n",
    "                \n",
    "                for max_iteration in [10, 100, 1000, 10000]:\n",
    "                        \n",
    "                    # Initialize U and V\n",
    "                    K = k # Here is where we choose the number of latent factors we would like to include in our matrices.\n",
    "                    I = len(user_idx) # number of users\n",
    "                    M = len(item_idx) # number of items\n",
    "                    U = np.random.uniform(0, 1, size=K*I).reshape((K, I))\n",
    "                    V = np.random.uniform(0, 1, size=K*M).reshape((K, M))\n",
    "                    # if j == 0:\n",
    "                    #     if clustering == \"item\": \n",
    "                    #         item_features = item_features.groupby('cluster').agg(sum)\n",
    "                    #         U = np.concatenate((U, user_features.iloc[:, 3:].T), axis=0)\n",
    "                    #         V = np.concatenate((V, item_features.iloc[:, 3:].T), axis=0)\n",
    "\n",
    "\n",
    "                    U, V, track_error, track_update = matrix_modules.alternating_least_squares(U, V, R, user_idx, item_idx, max_iterations=max_iteration, lambda_reg=lambda_reg)\n",
    "                    param_info = pd.DataFrame(data={\"clustering_type\": clustering, \"alg\" : \"ALS\", \"k\" : k, \"lambda_reg\" : lambda_reg, 'RMSE' : [track_error], 'Max Updates' : [track_update]}, index=[counter])\n",
    "                    counter += 1\n",
    "                    results = pd.concat([results, param_info], axis=0)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clustering_type</th>\n",
       "      <th>alg</th>\n",
       "      <th>k</th>\n",
       "      <th>lambda_reg</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Max Updates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item</td>\n",
       "      <td>ALS</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[1.303687239041997, 1.134792016496023, 1.09508...</td>\n",
       "      <td>[2642176.476173698, 1004851.1854146038, 393105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item</td>\n",
       "      <td>ALS</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[1.3529698022025411, 1.1695424551258982, 1.113...</td>\n",
       "      <td>[5731861.88477129, 954607.0524404056, 909359.5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  clustering_type  alg  k  lambda_reg  \\\n",
       "0            item  ALS  5        0.01   \n",
       "1            item  ALS  5        0.01   \n",
       "\n",
       "                                                RMSE  \\\n",
       "0  [1.303687239041997, 1.134792016496023, 1.09508...   \n",
       "1  [1.3529698022025411, 1.1695424551258982, 1.113...   \n",
       "\n",
       "                                         Max Updates  \n",
       "0  [2642176.476173698, 1004851.1854146038, 393105...  \n",
       "1  [5731861.88477129, 954607.0524404056, 909359.5...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item embeddings found, loading now\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>popularity</th>\n",
       "      <th>autos</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>finance</th>\n",
       "      <th>foodanddrink</th>\n",
       "      <th>games</th>\n",
       "      <th>health</th>\n",
       "      <th>...</th>\n",
       "      <th>watch</th>\n",
       "      <th>weatherfullscreenmaps</th>\n",
       "      <th>weathertopstories</th>\n",
       "      <th>weight-loss</th>\n",
       "      <th>weightloss</th>\n",
       "      <th>wellness</th>\n",
       "      <th>wines</th>\n",
       "      <th>wonder</th>\n",
       "      <th>yearinoffbeatgoodnews</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N88753</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "      <td>Shop the notebooks, jackets, and more that the...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N23144</td>\n",
       "      <td>50 Worst Habits For Belly Fat</td>\n",
       "      <td>These seemingly harmless habits are holding yo...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N86255</td>\n",
       "      <td>Dispose of unwanted prescription drugs during ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N93187</td>\n",
       "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
       "      <td>Lt. Ivan Molchanets peeked over a parapet of s...</td>\n",
       "      <td>221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N75236</td>\n",
       "      <td>I Was An NBA Wife. Here's How It Affected My M...</td>\n",
       "      <td>I felt like I was a fraud, and being an NBA wi...</td>\n",
       "      <td>1525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72018</th>\n",
       "      <td>N99177</td>\n",
       "      <td>Why Kate &amp; Meghan Were on Different Balconies ...</td>\n",
       "      <td>There's no scandal here. It's all about the or...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72019</th>\n",
       "      <td>N97143</td>\n",
       "      <td>See the stars at the 2019 Baby2Baby gala</td>\n",
       "      <td>Stars like Chrissy Teigen and Kate Hudson supp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72020</th>\n",
       "      <td>N57903</td>\n",
       "      <td>Tennessee judge holds lawyer's baby as he swea...</td>\n",
       "      <td>Tennessee Court of Appeals Judge Richard Dinki...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72021</th>\n",
       "      <td>N74617</td>\n",
       "      <td>Best Sports Car Deals for October</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72022</th>\n",
       "      <td>N56840</td>\n",
       "      <td>Shall we dance: Sports stars shake their leg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72023 rows × 274 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      news_id                                              title  \\\n",
       "0      N88753  The Brands Queen Elizabeth, Prince Charles, an...   \n",
       "1      N23144                      50 Worst Habits For Belly Fat   \n",
       "2      N86255  Dispose of unwanted prescription drugs during ...   \n",
       "3      N93187  The Cost of Trump's Aid Freeze in the Trenches...   \n",
       "4      N75236  I Was An NBA Wife. Here's How It Affected My M...   \n",
       "...       ...                                                ...   \n",
       "72018  N99177  Why Kate & Meghan Were on Different Balconies ...   \n",
       "72019  N97143           See the stars at the 2019 Baby2Baby gala   \n",
       "72020  N57903  Tennessee judge holds lawyer's baby as he swea...   \n",
       "72021  N74617                  Best Sports Car Deals for October   \n",
       "72022  N56840       Shall we dance: Sports stars shake their leg   \n",
       "\n",
       "                                                abstract  popularity  autos  \\\n",
       "0      Shop the notebooks, jackets, and more that the...          10    0.0   \n",
       "1      These seemingly harmless habits are holding yo...           5    0.0   \n",
       "2                                                    NaN           8    0.0   \n",
       "3      Lt. Ivan Molchanets peeked over a parapet of s...         221    0.0   \n",
       "4      I felt like I was a fraud, and being an NBA wi...        1525    0.0   \n",
       "...                                                  ...         ...    ...   \n",
       "72018  There's no scandal here. It's all about the or...           0    0.0   \n",
       "72019  Stars like Chrissy Teigen and Kate Hudson supp...           0    0.0   \n",
       "72020  Tennessee Court of Appeals Judge Richard Dinki...           2    0.0   \n",
       "72021                                                NaN           1    1.0   \n",
       "72022                                                NaN           2    0.0   \n",
       "\n",
       "       entertainment  finance  foodanddrink  games  health  ...  watch  \\\n",
       "0                0.0      0.0           0.0    0.0     0.0  ...    0.0   \n",
       "1                0.0      0.0           0.0    0.0     1.0  ...    0.0   \n",
       "2                0.0      0.0           0.0    0.0     1.0  ...    0.0   \n",
       "3                0.0      0.0           0.0    0.0     0.0  ...    0.0   \n",
       "4                0.0      0.0           0.0    0.0     1.0  ...    0.0   \n",
       "...              ...      ...           ...    ...     ...  ...    ...   \n",
       "72018            0.0      0.0           0.0    0.0     0.0  ...    0.0   \n",
       "72019            1.0      0.0           0.0    0.0     0.0  ...    0.0   \n",
       "72020            0.0      0.0           0.0    0.0     0.0  ...    0.0   \n",
       "72021            0.0      0.0           0.0    0.0     0.0  ...    0.0   \n",
       "72022            0.0      0.0           0.0    0.0     0.0  ...    0.0   \n",
       "\n",
       "       weatherfullscreenmaps  weathertopstories  weight-loss  weightloss  \\\n",
       "0                        0.0                0.0          0.0         0.0   \n",
       "1                        0.0                0.0          0.0         1.0   \n",
       "2                        0.0                0.0          0.0         0.0   \n",
       "3                        0.0                0.0          0.0         0.0   \n",
       "4                        0.0                0.0          0.0         0.0   \n",
       "...                      ...                ...          ...         ...   \n",
       "72018                    0.0                0.0          0.0         0.0   \n",
       "72019                    0.0                0.0          0.0         0.0   \n",
       "72020                    0.0                0.0          0.0         0.0   \n",
       "72021                    0.0                0.0          0.0         0.0   \n",
       "72022                    0.0                0.0          0.0         0.0   \n",
       "\n",
       "       wellness  wines  wonder  yearinoffbeatgoodnews  cluster  \n",
       "0           0.0    0.0     0.0                    0.0      117  \n",
       "1           0.0    0.0     0.0                    0.0      136  \n",
       "2           0.0    0.0     0.0                    0.0       49  \n",
       "3           0.0    0.0     0.0                    0.0       15  \n",
       "4           0.0    0.0     0.0                    0.0      137  \n",
       "...         ...    ...     ...                    ...      ...  \n",
       "72018       0.0    0.0     0.0                    0.0      117  \n",
       "72019       0.0    0.0     0.0                    0.0      186  \n",
       "72020       0.0    0.0     0.0                    0.0       57  \n",
       "72021       0.0    0.0     0.0                    0.0       79  \n",
       "72022       0.0    0.0     0.0                    0.0      109  \n",
       "\n",
       "[72023 rows x 274 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features = pd.read_csv(\"../MIND_large/csv/item_features.csv\", index_col=0)\n",
    "item_features = cm.item_cluster(item_features, 100)\n",
    "item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features.to_csv(\"../MIND_large/csv/item_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "ratings, news, users = matrix_modules.load_dataset_for_matrix()\n",
    "\n",
    "# create the matrix and user \n",
    "R, D = matrix_modules.create_item_cluster_mat(ratings, news, num_users=len(users), num_clusters=len(news['cluster'].unique()), isALS=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.41665739, -0.41665739,  0.73680101, ...,  0.        ,\n",
       "        -0.41665739,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.16007181,  0.        , ...,  0.        ,\n",
       "         0.        , -0.41665739],\n",
       "       [ 0.        , -0.41665739,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.41665739,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero = R != 0\n",
    "A_mean = np.mean(R[non_zero])\n",
    "A_std = np.std(R[non_zero])\n",
    "\n",
    "# Ensure A_std is not zero to avoid division by zero\n",
    "epsilon = 1e-8  # A small value\n",
    "A_standardized = np.where(R!=0, (R - A_mean) / (A_std + epsilon), 0)\n",
    "\n",
    "A_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.0106383 , 0.0106383 , 0.03191489, ..., 0.        , 0.0106383 ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.0212766 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.0106383 ],\n",
       "       [0.        , 0.0106383 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.0106383 , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_normalized = np.where(R!=0, (R - R.min()) / (R.max() - R.min()), 0)\n",
    "A_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255985</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255986</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255987</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255988</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255989</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255990 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1   2   3   4   5   6   7   8   9   ...  90  91  92  93  94  95  \\\n",
       "0        0   0   0   1   1   0   0   0   2   0  ...   1   0   0   0   0   0   \n",
       "1        1   1   3   0   1   0   0   1   1   0  ...   1   0   0   1   0   0   \n",
       "2        0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "3        0  11   1   0   2   0   0   0   4   0  ...   2   3   0   1   0   0   \n",
       "4        0   9   2   1   0   0   1   0   0   1  ...   1   1   0   2   1   0   \n",
       "...     ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
       "255985   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "255986   0   1   0   0   0   0   0   0   1   0  ...   0   0   0   0   0   0   \n",
       "255987   0   2   0   0   0   0   0   0   1   0  ...   1   0   1   1   0   0   \n",
       "255988   0   1   0   0   0   0   0   0   1   0  ...   0   0   0   0   0   0   \n",
       "255989   1   0   0   0   0   0   0   1   0   0  ...   1   0   0   0   0   0   \n",
       "\n",
       "        96  97  98  99  \n",
       "0        0   0   0   0  \n",
       "1        0   0   1   0  \n",
       "2        0   0   0   0  \n",
       "3        0   0   0   0  \n",
       "4        0   0   1   0  \n",
       "...     ..  ..  ..  ..  \n",
       "255985   0   0   0   0  \n",
       "255986   0   0   0   0  \n",
       "255987   0   0   0   1  \n",
       "255988   0   0   0   0  \n",
       "255989   0   0   0   0  \n",
       "\n",
       "[255990 rows x 100 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# initialize a dataframe of the matrix to look at data\n",
    "df = pd.DataFrame(R)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117021</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095745</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255985</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255986</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255987</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255988</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255989</th>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255990 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4    5         6   \\\n",
       "0       0.000000  0.000000  0.000000  0.010638  0.010638  0.0  0.000000   \n",
       "1       0.010638  0.010638  0.031915  0.000000  0.010638  0.0  0.000000   \n",
       "2       0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "3       0.000000  0.117021  0.010638  0.000000  0.021277  0.0  0.000000   \n",
       "4       0.000000  0.095745  0.021277  0.010638  0.000000  0.0  0.010638   \n",
       "...          ...       ...       ...       ...       ...  ...       ...   \n",
       "255985  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "255986  0.000000  0.010638  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "255987  0.000000  0.021277  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "255988  0.000000  0.010638  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "255989  0.010638  0.000000  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "\n",
       "              7         8         9   ...        90        91        92  \\\n",
       "0       0.000000  0.021277  0.000000  ...  0.010638  0.000000  0.000000   \n",
       "1       0.010638  0.010638  0.000000  ...  0.010638  0.000000  0.000000   \n",
       "2       0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "3       0.000000  0.042553  0.000000  ...  0.021277  0.031915  0.000000   \n",
       "4       0.000000  0.000000  0.010638  ...  0.010638  0.010638  0.000000   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "255985  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "255986  0.000000  0.010638  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "255987  0.000000  0.010638  0.000000  ...  0.010638  0.000000  0.010638   \n",
       "255988  0.000000  0.010638  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "255989  0.010638  0.000000  0.000000  ...  0.010638  0.000000  0.000000   \n",
       "\n",
       "              93        94   95   96   97        98        99  \n",
       "0       0.000000  0.000000  0.0  0.0  0.0  0.000000  0.000000  \n",
       "1       0.010638  0.000000  0.0  0.0  0.0  0.010638  0.000000  \n",
       "2       0.000000  0.000000  0.0  0.0  0.0  0.000000  0.000000  \n",
       "3       0.010638  0.000000  0.0  0.0  0.0  0.000000  0.000000  \n",
       "4       0.021277  0.010638  0.0  0.0  0.0  0.010638  0.000000  \n",
       "...          ...       ...  ...  ...  ...       ...       ...  \n",
       "255985  0.000000  0.000000  0.0  0.0  0.0  0.000000  0.000000  \n",
       "255986  0.000000  0.000000  0.0  0.0  0.0  0.000000  0.000000  \n",
       "255987  0.010638  0.000000  0.0  0.0  0.0  0.000000  0.010638  \n",
       "255988  0.000000  0.000000  0.0  0.0  0.0  0.000000  0.000000  \n",
       "255989  0.000000  0.000000  0.0  0.0  0.0  0.000000  0.000000  \n",
       "\n",
       "[255990 rows x 100 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(A_normalized)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should consider scaling ratings in matrices to be more normal and on a zero to one scale, this could heavily impact the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Optimized Gradient Descent: 100%|██████████| 100/100 [00:34<00:00,  2.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.85273994, 0.05665476, 0.24194324, 0.64793738, 0.12865943],\n",
       "       [0.60427479, 0.03818532, 0.94338069, 0.96376795, 0.50600693],\n",
       "       [0.62973647, 0.75769151, 0.75799389, 0.41119076, 0.76192699],\n",
       "       ...,\n",
       "       [0.10999535, 0.14362204, 0.94358846, 0.21634797, 0.90723196],\n",
       "       [0.50684018, 0.46581088, 0.66074657, 0.01370569, 0.98440865],\n",
       "       [0.2418466 , 0.89339888, 0.36010946, 0.77464585, 0.41598634]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize U and V\n",
    "K = 5 # five latent factors tentatively \n",
    "I = len(users) # number of users\n",
    "M = 100 # number of items\n",
    "np.random.seed(52)\n",
    "U = np.random.uniform(0, 1, size=K*I).reshape((I, K))\n",
    "V = np.random.uniform(0, 1, size=K*M).reshape((M, K))\n",
    "\n",
    "def vectorized_gradient_descent(R,U,V, D, rate=0.00001,max_iterations=10,lam=5, diff_threshold=1e-3):\n",
    "    \"\"\"\n",
    "    Performes vectorized gradient descent to make ratings predictions for the incomplete user-item matrix. Compared to standard gradient descent, \n",
    "    vectorized gradient descent further improves upon update formulae by using matrices Gamma and D to operate on U and V for observed ratings \n",
    "    instead of iterating over all observed indices.\n",
    "\n",
    "    Args:\n",
    "        R (np.ndarray) : The user-item ratings matrix R.\n",
    "        U (np.ndarray) : The user latent factor matrix U.\n",
    "        V (np.ndarray) : The item latent factor matrix V.\n",
    "        D (np.ndarray) : The observed interaction matrix D.\n",
    "        rate (float) : The learning rate for the gradient descent. Here we need to use small values like 0.00001 due to \n",
    "            the numerical instability of our data brought on by clustering.\n",
    "        max_iterations (int) : The number of iterations to run gradient descent for.\n",
    "        lam (float) : The regularization parameter which adds a penalty to vectors with large magnitude.\n",
    "        diff_threshold (float) : The threshold to stop iterating over the data with to avoid computational innefficiency.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create initial Uold and Vold for calculating max updates.\n",
    "    Uold = np.zeros_like(U)\n",
    "    Vold = np.zeros_like(V)\n",
    "    \n",
    "    # Initialize empty lists to track error and update.\n",
    "    error_update = []\n",
    "    track_update = []\n",
    "\n",
    "    # Perform gradient descent for the number of iterations as specified by max_iterations.\n",
    "    for t in tqdm(range(1, max_iterations+1), total=max_iterations, desc='Running Optimized Gradient Descent'): # , total=max_iterations, desc=\"Starting descent\"):\n",
    "\n",
    "        # Create Gamma as the residuals matrix.\n",
    "        Gamma = R - (U @ V.T)\n",
    "\n",
    "        # Take the hadamard product of gamma and matrix D to get a matrix of all observed residuals.\n",
    "        observed_errors = np.multiply(Gamma, D)\n",
    "\n",
    "        # Update the entire matrix U with vectorized operations.\n",
    "        U += rate * (observed_errors @ V - lam * U)\n",
    "        \n",
    "        # Find Gamma and observed_errors with the updated U.    \n",
    "        Gamma = R-(U @ V.T)\n",
    "        observed_errors = np.multiply(Gamma, D)\n",
    "\n",
    "        # Update the entire matrix V with vectorized operations.\n",
    "        V += rate * (observed_errors.T @ U - lam * V)\n",
    "\n",
    "        # Update the update tracking.    \n",
    "        track_update += [\n",
    "            max(max_update(U, Uold), max_update(V, Vold))\n",
    "        ]\n",
    "\n",
    "        # If our most recent update is lower than our difference threshold, return the Old matrices and information arrays.\n",
    "        if track_update[-1] < diff_threshold:\n",
    "            print(\"Threshold reached, stopping descent\")\n",
    "            return Uold, Vold , error_update, track_update\n",
    "\n",
    "        # Update Uold and Vold.\n",
    "        Uold = U.copy() \n",
    "        Vold = V.copy()\n",
    "\n",
    "        # Update the error.\n",
    "        error_update += [rmse(observed_errors)]\n",
    "    \n",
    "    # Return the new U and V and update lists. \n",
    "    return U, V , error_update, track_update\n",
    "\n",
    "U, V, error, updates = vectorized_gradient_descent(R, U, V, D, lam=1, rate=0.00001, max_iterations=100)\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clustering_type</th>\n",
       "      <th>alg</th>\n",
       "      <th>k</th>\n",
       "      <th>lambda_reg</th>\n",
       "      <th>umapDim</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Max Updates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clustering</td>\n",
       "      <td>ALS</td>\n",
       "      <td>k</td>\n",
       "      <td>lambda_reg</td>\n",
       "      <td>umapDim</td>\n",
       "      <td>[1.8604034732010815, 1.767962142452612, 1.7562...</td>\n",
       "      <td>[1.7976931348623157e+308, 78.00435501548826, 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  clustering_type  alg  k  lambda_reg  umapDim  \\\n",
       "0      clustering  ALS  k  lambda_reg  umapDim   \n",
       "\n",
       "                                                RMSE  \\\n",
       "0  [1.8604034732010815, 1.767962142452612, 1.7562...   \n",
       "\n",
       "                                         Max Updates  \n",
       "0  [1.7976931348623157e+308, 78.00435501548826, 7...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_info = pd.DataFrame(data={\"clustering_type\": 'clustering', \"alg\" : \"ALS\", \"k\" : 'k', \"lambda_reg\" : 'lambda_reg', \"umapDim\": 'umapDim', 'RMSE' : [error], 'Max Updates' : [updates]}, index=[0])\n",
    "param_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.860403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.767962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.756226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.751660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.749252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>1.713117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>1.712820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>1.712524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>1.712228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>1.711933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    iter      rmse\n",
       "0      1  1.860403\n",
       "1      2  1.767962\n",
       "2      3  1.756226\n",
       "3      4  1.751660\n",
       "4      5  1.749252\n",
       "..   ...       ...\n",
       "95    96  1.713117\n",
       "96    97  1.712820\n",
       "97    98  1.712524\n",
       "98    99  1.712228\n",
       "99   100  1.711933\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df = pd.DataFrame(error)\n",
    "error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [rmse for rmse in [track_error[i]['rmse'] for i in range(len(track_error))]]\n",
    "max_updates = [update for update in [track_update[i]['max_update'] for i in range(len(track_update))]]\n",
    "print(errors)\n",
    "print(max_updates)\n",
    "param_info = pd.DataFrame(data={\"clustering_type\": clustering, \"alg\" : \"ALS\", \"k\" : k, \"lambda_reg\" : lambda_reg, \"umapDim\": umapDim, 'RMSE' : [errors], 'Max Updates' : [max_updates]}, index=[counter])\n",
    "counter += 1\n",
    "results = pd.concat([results, param_info], axis=0)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_sgd(error):\n",
    "    # plots rsme as SGD iterates\n",
    "    error_df = pd.DataFrame(error, columns=[\"iter\", \"rmse\"])\n",
    "    plt.plot(error_df[\"iter\"], error_df[\"rmse\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_error_sgd(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating Over R:   7%|▋         | 248395/3808726 [00:03<00:51, 69660.27it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 53\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m U, V , error_update, track_update\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# U, V = SGD(R, U, V)\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m U, V, error, updates \u001b[38;5;241m=\u001b[39m \u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m U\n",
      "Cell \u001b[0;32mIn[17], line 23\u001b[0m, in \u001b[0;36mSGD\u001b[0;34m(R, U, V, rate, max_iterations, lam, diff_threshold)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Calculate the error again with updated U[i] and then update V[m]\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     error \u001b[38;5;241m=\u001b[39m R[i, m] \u001b[38;5;241m-\u001b[39m (V[m] \u001b[38;5;241m*\u001b[39m U[i])\n\u001b[0;32m---> 23\u001b[0m     V[m] \u001b[38;5;241m=\u001b[39m V[m] \u001b[38;5;241m+\u001b[39m ((\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m rate \u001b[38;5;241m*\u001b[39m error) \u001b[38;5;241m*\u001b[39m U[i]) \u001b[38;5;241m-\u001b[39m v_penalty\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# track_rmse += [{\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#     'iteration':i, \u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#     'rmse': rmse(Gnew),\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#     'max residual change': max_update(Gnew, G, relative=False)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# }]\u001b[39;00m\n\u001b[1;32m     30\u001b[0m track_update \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [{\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miteration\u001b[39m\u001b[38;5;124m'\u001b[39m:t, \n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax update\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mmax\u001b[39m(max_update(U, Uold), max_update(V, Vold))\n\u001b[1;32m     33\u001b[0m }]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def gradient_descent(R,U,V,rate=0.01,max_iterations=10,lam=5, diff_threshold=1e-3):\n",
    "    \"\"\"\n",
    "    Performes vectorized gradient descent to make ratings predictions for the incomplete user-item matrix. Compared to standard gradient descent, \n",
    "    vectorized gradient descent further improves upon update formulae by using matrices Gamma and D to operate on U and V for observed ratings \n",
    "    instead of iterating over all observed indices.\n",
    "\n",
    "    Args:\n",
    "        R (np.ndarray) : The user-item ratings matrix R.\n",
    "        U (np.ndarray) : The user latent factor matrix U.\n",
    "        V (np.ndarray) : The item latent factor matrix V.\n",
    "        rate (float) : The learning rate for the gradient descent. Here we need to use small values like 0.00001 due to \n",
    "            the numerical instability of our data brought on by clustering.\n",
    "        max_iterations (int) : The number of iterations to run gradient descent for.\n",
    "        lam (float) : The regularization parameter which adds a penalty to vectors with large magnitude.\n",
    "        diff_threshold (float) : The threshold to stop iterating over the data with to avoid computational innefficiency.\n",
    "    \"\"\"\n",
    "    # Create initial Uold and Vold for calculating max updates.\n",
    "    Uold = np.zeros_like(U)\n",
    "    Vold = np.zeros_like(V)\n",
    "\n",
    "    # Initialize empty lists to track error and update.\n",
    "    error_update = []\n",
    "    track_update = []\n",
    "\n",
    "    # Perform gradient descent for the number of iterations as specified by max_iterations.\n",
    "    for t in range(1, max_iterations):\n",
    "        \n",
    "        # Iterate over all row and column indices in R where there is not a zero.\n",
    "        for i, m in tqdm(zip(*np.where(R != 0)), total=len(np.where(R != 0)[0]), desc=\"Iterating Over R\", leave=True):\n",
    "\n",
    "            # Calculate the penalty terms.\n",
    "            u_penalty = 2 * rate * lam * U[i]\n",
    "            v_penalty = 2 * rate * lam * V[m]\n",
    "\n",
    "            # Calculate the error and then update U[i]\n",
    "            error = R[i, m] - (V[m] * U[i])\n",
    "            U[i] = U[i] + ((2 * rate * error) * V[m]) - u_penalty\n",
    "\n",
    "            # Calculate the error again with updated U[i] and then update V[m]\n",
    "            error = R[i, m] - (V[m] * U[i])\n",
    "            V[m] = V[m] + ((2 * rate * error) * U[i]) - v_penalty\n",
    "\n",
    "        # Update the update tracking.    \n",
    "        track_update += [{\n",
    "            'iteration':t, \n",
    "            'max update':max(max_update(U, Uold), max_update(V, Vold))\n",
    "        }]\n",
    "\n",
    "        # Update Uold and Vold.\n",
    "        Uold = U.copy()\n",
    "        Vold = V.copy()\n",
    "\n",
    "        # If our most recent update is lower than our difference threshold, return the Old matrices and information arrays.\n",
    "        if track_update[-1] < diff_threshold:\n",
    "            print(\"Threshold reached, stopping descent\")\n",
    "            return Uold, Vold , error_update, track_update\n",
    "        \n",
    "        # compute error after one sweep of updates\n",
    "        error_update += [(t, rmse(R-(U @ V.T)))]\n",
    "        \n",
    "    return U, V , error_update, track_update\n",
    "\n",
    "# U, V = SGD(R, U, V)\n",
    "\n",
    "U, V, error, updates = gradient_descent(R, U, V, max_iterations=5)\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1, rmse(R-(U @ V.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iter(x, rmse_test, hyper_param, burn_in):\n",
    "  fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, figsize=(15, 8))\n",
    "\n",
    "  axes[0, 0].plot(x, rmse_test[burn_in:], label='test rmse', color=\"r\")\n",
    "  axes[0, 0].legend()\n",
    "  axes[0, 1].plot(x, hyper_param[burn_in:,0], label='alpha', color=\"b\")\n",
    "  axes[0, 1].legend()\n",
    "  axes[1, 0].plot(x, hyper_param[burn_in:,1], label='lambda_w', color=\"g\")\n",
    "  axes[1, 0].legend()\n",
    "  axes[1, 1].plot(x, hyper_param[burn_in:,3], label='mu_w', color=\"g\")\n",
    "  axes[1, 1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(U @ V.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
