{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 04:57:29.936538: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-20 04:57:30.131095: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-20 04:57:30.883011: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-20 04:57:32.987593: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Text\n",
    "EMB_DIM=32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "      <th>news_id</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>interaction_type</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U66319</td>\n",
       "      <td>1</td>\n",
       "      <td>N10721</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>entertainment-celebrity</td>\n",
       "      <td>Mike Johnson asks out Keke Palmer after Demi L...</td>\n",
       "      <td>Mike Johnson tried to ask out Keke Palmer in a...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U66319</td>\n",
       "      <td>1</td>\n",
       "      <td>N128129</td>\n",
       "      <td>movies</td>\n",
       "      <td>movies-celebrity</td>\n",
       "      <td>Brie Larson Has the Best Reaction Ever After T...</td>\n",
       "      <td>The 'Captain Marvel' star was left speechless ...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U66319</td>\n",
       "      <td>1</td>\n",
       "      <td>N28406</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>Accused dine-and-dashers in viral video at St....</td>\n",
       "      <td>Five young black men who posted a video of a m...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U66319</td>\n",
       "      <td>1</td>\n",
       "      <td>N118998</td>\n",
       "      <td>news</td>\n",
       "      <td>newsgoodnews</td>\n",
       "      <td>Trooper pulls over to save flag on highway</td>\n",
       "      <td>The trooper is being praised for stopping his ...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U66319</td>\n",
       "      <td>1</td>\n",
       "      <td>N38884</td>\n",
       "      <td>sports</td>\n",
       "      <td>mma</td>\n",
       "      <td>UFC champ Khabib Nurmagomedov seen training in...</td>\n",
       "      <td>Khabib Nurmagomedov doesn't mess around.</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20645888</th>\n",
       "      <td>U491432</td>\n",
       "      <td>0</td>\n",
       "      <td>N87192</td>\n",
       "      <td>finance</td>\n",
       "      <td>finance-companies</td>\n",
       "      <td>Bill Gates tops Jeff Bezos as world's richest ...</td>\n",
       "      <td>This time it's official.</td>\n",
       "      <td>impression</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20645889</th>\n",
       "      <td>U491432</td>\n",
       "      <td>0</td>\n",
       "      <td>N31918</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>Oscar Wilde's stolen ring found by Dutch 'art ...</td>\n",
       "      <td>A golden ring once given as a present by the f...</td>\n",
       "      <td>impression</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20645890</th>\n",
       "      <td>U491432</td>\n",
       "      <td>0</td>\n",
       "      <td>N73556</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_nfl</td>\n",
       "      <td>Report: At least 24 teams expected to attend K...</td>\n",
       "      <td>It looks like the majority of the teams in the...</td>\n",
       "      <td>impression</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20645891</th>\n",
       "      <td>U491432</td>\n",
       "      <td>0</td>\n",
       "      <td>N92223</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestylebuzz</td>\n",
       "      <td>This 10-Year-Old Girl's Demanding Christmas Wi...</td>\n",
       "      <td>A father recently shared his 10-year-old daugh...</td>\n",
       "      <td>impression</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20645892</th>\n",
       "      <td>U491432</td>\n",
       "      <td>0</td>\n",
       "      <td>N114517</td>\n",
       "      <td>sports</td>\n",
       "      <td>baseball_mlb</td>\n",
       "      <td>MLB GM wants Jeff Luhnow 'banned for life' if ...</td>\n",
       "      <td>Another team executive said he wanted to see t...</td>\n",
       "      <td>impression</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20645893 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  time  news_id       category             sub_category  \\\n",
       "0          U66319     1   N10721  entertainment  entertainment-celebrity   \n",
       "1          U66319     1  N128129         movies         movies-celebrity   \n",
       "2          U66319     1   N28406           news                newsworld   \n",
       "3          U66319     1  N118998           news             newsgoodnews   \n",
       "4          U66319     1   N38884         sports                      mma   \n",
       "...           ...   ...      ...            ...                      ...   \n",
       "20645888  U491432     0   N87192        finance        finance-companies   \n",
       "20645889  U491432     0   N31918           news                newsworld   \n",
       "20645890  U491432     0   N73556         sports             football_nfl   \n",
       "20645891  U491432     0   N92223      lifestyle            lifestylebuzz   \n",
       "20645892  U491432     0  N114517         sports             baseball_mlb   \n",
       "\n",
       "                                                      title  \\\n",
       "0         Mike Johnson asks out Keke Palmer after Demi L...   \n",
       "1         Brie Larson Has the Best Reaction Ever After T...   \n",
       "2         Accused dine-and-dashers in viral video at St....   \n",
       "3                Trooper pulls over to save flag on highway   \n",
       "4         UFC champ Khabib Nurmagomedov seen training in...   \n",
       "...                                                     ...   \n",
       "20645888  Bill Gates tops Jeff Bezos as world's richest ...   \n",
       "20645889  Oscar Wilde's stolen ring found by Dutch 'art ...   \n",
       "20645890  Report: At least 24 teams expected to attend K...   \n",
       "20645891  This 10-Year-Old Girl's Demanding Christmas Wi...   \n",
       "20645892  MLB GM wants Jeff Luhnow 'banned for life' if ...   \n",
       "\n",
       "                                                   abstract interaction_type  \\\n",
       "0         Mike Johnson tried to ask out Keke Palmer in a...          history   \n",
       "1         The 'Captain Marvel' star was left speechless ...          history   \n",
       "2         Five young black men who posted a video of a m...          history   \n",
       "3         The trooper is being praised for stopping his ...          history   \n",
       "4                  Khabib Nurmagomedov doesn't mess around.          history   \n",
       "...                                                     ...              ...   \n",
       "20645888                           This time it's official.       impression   \n",
       "20645889  A golden ring once given as a present by the f...       impression   \n",
       "20645890  It looks like the majority of the teams in the...       impression   \n",
       "20645891  A father recently shared his 10-year-old daugh...       impression   \n",
       "20645892  Another team executive said he wanted to see t...       impression   \n",
       "\n",
       "          score  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "...         ...  \n",
       "20645888      0  \n",
       "20645889      0  \n",
       "20645890      0  \n",
       "20645891      0  \n",
       "20645892      0  \n",
       "\n",
       "[20645893 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading in the dataset\n",
    "dataset=pd.DataFrame()\n",
    "for i in range(4):\n",
    "    df = pd.read_csv(f\"../MIND_large/csv/tensorflow_dataset_chunk{i}.csv\", index_col=0)\n",
    "    dataset = pd.concat([dataset, df])\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72645/3896519647.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split['score'] = split['score'].astype('float32')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "user_id              object\n",
       "time                  int64\n",
       "news_id              object\n",
       "category             object\n",
       "sub_category         object\n",
       "title                object\n",
       "abstract             object\n",
       "interaction_type     object\n",
       "score               float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = dataset[dataset.index < 45893]\n",
    "split['score'] = split['score'].astype('float32')\n",
    "split.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72645/2653686252.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# removing the NaN values from the dataset and changing the dataset type into a tensorflow dataset.\n",
    "split.dropna(inplace=True)\n",
    "news = pd.read_csv(\"../MIND_large/csv/news.csv\", index_col=0)\n",
    "news.drop(columns=['url', 'title_entities', 'abstract_entities'], inplace=True)\n",
    "news.dropna(inplace=True)\n",
    "tf_ds = tf.data.Dataset.from_tensor_slices(dict(split))\n",
    "catalog_ds = tf.data.Dataset.from_tensor_slices(dict(news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping all features to relevant items in the map dataset\n",
    "ratings_ds = tf_ds.map(lambda x : {\n",
    "    'user_id' : x['user_id'],\n",
    "    'time' : x['time'],\n",
    "    'category' : x['category'],\n",
    "    'sub_category' : x['sub_category'],\n",
    "    'title' : x['title'],\n",
    "    'abstract' : x['abstract'],\n",
    "    'score' : x['score']\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping all features to relevant items in the map dataset\n",
    "news_ds = catalog_ds.map(lambda x : {\n",
    "    'news_id' : x['news_id'],\n",
    "    'category' : x['category'],\n",
    "    'sub_category' : x['sub_category'],\n",
    "    'title' : x['title'],\n",
    "    'abstract' : x['abstract']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 05:27:08.644561: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-03-20 05:27:09.234800: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Creating lists of all unique user and news ids\n",
    "unique_news_ids = np.unique(np.concatenate(list(news_ds.batch(1000).map(lambda x : x['news_id']))))\n",
    "unique_user_ids = np.unique(np.concatenate(list(ratings_ds.batch(1000).map(lambda x : x['user_id']))))\n",
    "# Output looks like array([b'U1', b'U100', b'U1000', ..., b'U99993', b'U99994', b'U99998'], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define the ranking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our ranking model, which is a subclass of the standard keras model. \n",
    "class newsRankingModel(keras.Model):\n",
    "\n",
    "    # Define the init method. \n",
    "    def __init__(self, embedding_dimension=32):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define the user ID model.\n",
    "        self.user_embeddings = keras.Sequential([\n",
    "            # Here we exclude the mask token as to better handle OOV items like new users or items.\n",
    "            keras.layers.StringLookup(vocabulary = unique_user_ids),\n",
    "\n",
    "            # Our final layer in the user ID model is an embedding layer which takes the IDs index\n",
    "            # and creates a dense vector representation of it.\n",
    "            keras.layers.Embedding(input_dim = len(unique_user_ids) + 1, output_dim = embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Define the news ID model.\n",
    "        self.news_embeddings = keras.Sequential([\n",
    "            # The news ID model is built the same way as the user ID model, just with different vocab and input dimensions.\n",
    "            keras.layers.StringLookup(vocabulary = unique_news_ids),\n",
    "            keras.layers.Embedding(input_dim = len(unique_news_ids) + 1, output_dim = embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Define the ratings model.\n",
    "        self.ratings = keras.Sequential([\n",
    "            # Initialize dense layers of neurons with the rectified linear unit activation function.\n",
    "            keras.layers.Dense(256, activation=\"relu\"),\n",
    "            keras.layers.Dense(64, activation=\"relu\"),\n",
    "            keras.layers.Dense(1)\n",
    "        ])\n",
    "    \n",
    "    # Define the call method, which performs actions on the data.\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Allows for the newsRankingModel to be called like a function. As an example, see the following:\n",
    "        newsRankingModel((features[\"user_id\"], features[\"movie_title\"])). In the most simple iteration of this ranking model\n",
    "        only the user and news ids are passed into the inputs argument. \n",
    "\n",
    "        Args:\n",
    "            inputs (tuple) : Inputs is a tuple of features being placed in the call to be extracted with the models \n",
    "            that were defined in the __init__ method.\n",
    "\n",
    "        Returns:\n",
    "            rating (int) : Returns a rating created by passing the elements of `inputs` into the embedding models and\n",
    "            the ratings model.\n",
    "        \"\"\"\n",
    "\n",
    "        # Extract the user and news IDs.\n",
    "        user_id, news_id = inputs\n",
    "\n",
    "        # Place the IDs through the embedding models.\n",
    "        user_embedding = self.user_embeddings(user_id)\n",
    "        news_embedding = self.news_embeddings(news_id)\n",
    "\n",
    "        # Concatenate the embedding vectors to one-another along the row axis.\n",
    "        rating = self.ratings(tf.concat([user_embedding, news_embedding], axis=1))\n",
    "\n",
    "        # Return the rating.\n",
    "        return rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MINDModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Within the larger model set the ranking model to the previously defined model above.\n",
    "        self.ranking_model = newsRankingModel()\n",
    "\n",
    "        # Set up the task of the recommender system.\n",
    "        self.task = tfrs.tasks.Ranking(\n",
    "\n",
    "            # Select the mean squared error loss function and the rmse for the ranking task and the metrics.\n",
    "            loss = keras.losses.MeanSquaredError(), # Can also swap this out for binary cross entropy, which might be nicer.\n",
    "            metrics = [keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def call(self, features):\n",
    "        \"\"\"\n",
    "        Allows for the MINDModel to be called like a function. As an example, see the following:\n",
    "        MINDModel({\"user_id\": np.array([\"U1\"]), \"news_id\": np.array([news_id])}) OR self(features). In the most simple iteration of MINDModel,\n",
    "        this function only takes inputs with the user_id and news_id. \n",
    "\n",
    "        Args:\n",
    "            inputs (tuple) : Inputs is a tuple of features being placed in the call to be extracted with the models \n",
    "            that were defined in the __init__ method.\n",
    "\n",
    "        Returns:\n",
    "            rating (int) : Returns a rating created by passing the elements of `inputs` into the embedding models and\n",
    "            the ratings model.\n",
    "        \"\"\"\n",
    "        items = self.ranking_model((features['user_id'], features['news_id']))\n",
    "        return items\n",
    "    \n",
    "    def compute_loss(self, features, training=False) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        Takes a set of features, unpacks them for the label and then makes a prediction on them using the models `call` method.\n",
    "        The prediction and label is then placed in the previously defined model task which seeks to minimize the mse with an rmse metric.\n",
    "        \"\"\"\n",
    "        # Get the label.\n",
    "        labels = features['score'] # change to be reflective of the score\n",
    "\n",
    "        # Get the predictions.\n",
    "        rating_predictions = self(features)\n",
    "\n",
    "        # Return the output from the task \n",
    "        return self.task(labels=labels, predictions=rating_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "45893 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72645/1798292297.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split.dropna(inplace=True)\n",
      "2024-03-20 05:34:39.454176: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-03-20 05:34:40.008158: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# removing the NaN values from the dataset and changing the dataset type into a tensorflow dataset.\n",
    "split.dropna(inplace=True)\n",
    "news = pd.read_csv(\"../MIND_large/csv/news.csv\", index_col=0)\n",
    "news.drop(columns=['url', 'title_entities', 'abstract_entities'], inplace=True)\n",
    "news.dropna(inplace=True)\n",
    "tf_ds = tf.data.Dataset.from_tensor_slices(dict(split))\n",
    "catalog_ds = tf.data.Dataset.from_tensor_slices(dict(news))\n",
    "# Mapping all features to relevant items in the map dataset\n",
    "ratings_ds = tf_ds.map(lambda x : {\n",
    "    'user_id' : x['user_id'],\n",
    "    'time' : x['time'],\n",
    "    'category' : x['category'],\n",
    "    'sub_category' : x['sub_category'],\n",
    "    'title' : x['title'],\n",
    "    'abstract' : x['abstract'],\n",
    "    'score' : x['score']\n",
    "})\n",
    "# Mapping all features to relevant items in the map dataset\n",
    "news_ds = catalog_ds.map(lambda x : {\n",
    "    'news_id' : x['news_id'],\n",
    "    'category' : x['category'],\n",
    "    'sub_category' : x['sub_category'],\n",
    "    'title' : x['title'],\n",
    "    'abstract' : x['abstract']\n",
    "})\n",
    "# Creating lists of all unique user and news ids\n",
    "unique_news_ids = np.unique(np.concatenate(list(news_ds.batch(1000).map(lambda x : x['news_id']))))\n",
    "unique_user_ids = np.unique(np.concatenate(list(ratings_ds.batch(1000).map(lambda x : x['user_id']))))\n",
    "# Output looks like array([b'U1', b'U100', b'U1000', ..., b'U99993', b'U99994', b'U99998'], dtype=object)\n",
    "tf.random.set_seed(42)\n",
    "shuffled = tf_ds.shuffle(10_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(30_000)\n",
    "test = shuffled.skip(30_000).take(15_893)\n",
    "cached_train = train.shuffle(10_000).batch(1000).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "model = MINDModel()\n",
    "model.compile(optimizer=keras.optimizers.Adagrad(learning_rate=0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/layer.py:359: UserWarning: `build()` was called on layer 'mind_model_8', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "2024-03-20 05:34:44.020988: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2461 - regularization_loss: 0.0000e+00 - total_loss: 0.2543 \n",
      "Epoch 2/3\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2351 - regularization_loss: 0.0000e+00 - total_loss: 0.2429\n",
      "Epoch 3/3\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2268 - regularization_loss: 0.0000e+00 - total_loss: 0.2344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f185461d950>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2201 - regularization_loss: 0.0000e+00 - total_loss: 0.2751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.0}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can include our ranking model within the larger MINDModel. Also of note is that Retrieval happens before Ranking in tensorflow modelling solutions, and that we should call the final step in matrix factorization methods something like \"making recommendations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we define a retrieval model\n",
    "class MINDModelRetrieval(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, embedding_dimension=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define the user ID model.\n",
    "        self.user_embeddings = keras.Sequential([\n",
    "            # Here we exclude the mask token as to better handle OOV items like new users or items.\n",
    "            keras.layers.StringLookup(vocabulary = unique_user_ids),\n",
    "\n",
    "            # Our final layer in the user ID model is an embedding layer which takes the IDs index\n",
    "            # and creates a dense vector representation of it.\n",
    "            keras.layers.Embedding(input_dim = len(unique_user_ids) + 1, output_dim = embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Define the news ID model.\n",
    "        self.news_embeddings = keras.Sequential([\n",
    "            # The news ID model is built the same way as the user ID model, just with different vocab and input dimensions.\n",
    "            keras.layers.StringLookup(vocabulary = unique_news_ids),\n",
    "            keras.layers.Embedding(input_dim = len(unique_user_ids) + 1, output_dim = embedding_dimension)\n",
    "        ])            \n",
    "\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics = tfrs.metrics.FactorizedTopK(candidates=news_ds.batch(128).map(self.news_embeddings))\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        Takes a set of features, unpacks them for the label and then makes a prediction on them using the models `call` method.\n",
    "        The prediction and label is then placed in the previously defined model task which seeks to minimize the mse with an rmse metric.\n",
    "        \"\"\"\n",
    "        # Get user_id embeddings.\n",
    "        user_id, news_id = features['user_id'], features['news_id']\n",
    "        user_vector = self.user_embeddings(user_id)\n",
    "\n",
    "        # Get the news_id embeddings.\n",
    "        news_vector = self.news_embeddings(news_id)\n",
    "\n",
    "        # Return the output from the task \n",
    "        return self.task(user_vector, news_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps:\n",
    "For tensorflow modelling after primary dataset transformations have been performed in order to create a compatible format for our data, we move on to initializing the models that will be performing our tasks. The most simple model in tensorflow would just be a ranking model that utilizes very few features from the data. \n",
    "\n",
    "Brief Note On Convenience:\n",
    "\n",
    "Tensorflow models are convenient in that we can start very simple and add complexity from the ground up by increasing the number of used features and adding more 'towers' to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Steps\n",
    "Across all levels of model complexity in tensorflow data processing is the first step. Tensorflow utilizes the tf.data.datasets module to make its models more efficient meaning that we had to change the format of our data from a pandas dataframe into a tf.data.datasets type. In order the steps we took are the following:\n",
    "\n",
    "* Casting the tensorflow compatible behaviors dataframe and catalog as tf.data.datasets objects using the tf.data.Dataset.from_tensor_slices()\n",
    "* Changing the format to a map dataset via the use of a lambda function which improves efficiency by modifying the dataset into a hash map like format.\n",
    "* Creating numpy arrays containing all unique user and news ids for later embedding layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Processing in Tensorflow\n",
    "Given our dataset we have a rich set of features: titles, abstracts, categories, sub categories, user preferences, time stamps and more. In a tensorflow environment (maybe irrelevant to work on or talk about here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking advantage of textual features like an articles abstract or title requires us to create a sequential model that pushes data through a text vectorization layer, an embedding layer, and then either a global average pooling function or something like an RNN or transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_title_tokens=32\n",
    "self.title_text_embedding = keras.Sequential([\n",
    "    keras.layers.TextVectorization(max_tokens=max_title_tokens),\n",
    "    keras.layers.Embedding(max_title_tokens, 32, mask_zero=True),\n",
    "    keras.layers.GlobalAveragePooling1D()\n",
    "])\n",
    "\n",
    "max_abstract_embeddings=32\n",
    "self.abstract_text_embedding = keras.Sequential([\n",
    "    keras.layers.TextVectorization(max_tokens=max_abstract_embeddings),\n",
    "    keras.layers.Embedding(max_abstract_embeddings, 32, mask_zero=True),\n",
    "    keras.layers.GlobalAveragePooling1D()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were utilizing unprocessed timestamps we would normally need to either standardize it with a normalization layer, or discretize it into bins. For matrix factorization based models we already discretized the time stamps into bins, took their median and then normalized them. However in the tensorflow compatible dataset only the binned time stamps are found therefore we implemented as keras sequential model to first discretize them and then a separate layer to normalize them. Then place them in an embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_vals = [] # populate with a list of all possible time stamp buckets\n",
    "self.timestamp_embedding = keras.Sequential([\n",
    "    keras.layers.Embedding(len(timestamp_vals) + 2, 32)\n",
    "])\n",
    "self.normalized_timestamp = keras.layers.Normalization(\n",
    "    axis=None\n",
    ")\n",
    "\n",
    "# then in our call function we access these timestamps in the following way\n",
    "self.timestamp_embedding(inputs['timestamp']), \n",
    "tf.reshape(self.normalized_timestamp(inputs['timestamp']), (-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about other features that we haven't discussed here? The features not discussed include: \n",
    "\n",
    "* ratings_ds = tf_ds.map(lambda x : {\n",
    "  *  'category' : x['category'],\n",
    "  *  'sub_category' : x['sub_category'],\n",
    "\n",
    "})\n",
    "* news_ds = catalog_ds.map(lambda x : {\n",
    "  *  'category' : x['category'],\n",
    "  *  'sub_category' : x['sub_category'],\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Tensorflow Models\n",
    "The most simple models at our disposal are single ranking or retreival models.\n",
    "\n",
    "### Ranking\n",
    "Given that we have our map dataset objects and unique user and item ID numpy arrays, we can initialize a simple ranking model. The ranking model uses the keras model as its super, in doing so we allow ourselves to incorporate our model into the keras ecosystem, define custom behavior and custom forward passes in our model and gaining access to features present in keras models like specific optimizers. \n",
    "\n",
    "The basic ranking model is comprised of three smaller keras sequential models: an embedding model for user IDs, an embedding model for news IDs, and a rating model to create rankings. \n",
    "\n",
    "Under the hood, these keras sequential models are initialized alongside keras.Model initialization and setting of a standard embedding dimension.\n",
    "\n",
    "#### Embedding Models\n",
    "Both embedding models are comprised of 2 layers: string lookup and embedding. The string lookup layer maps items on to unique indices utilizing the unique ID vocabularies generated during the initial processing of data. This index is then passed on to an embedding layer which creates dense vector representations of it using the previously defined embedding dimension. As the model trains these embeddings are updated to improve performance. Conveniently, these embedding layers generalize well to unseen data through the use of out of vocabulary tokens. Out of vocabulary tokens, or OOV, are generated when a new user or item is placed in the embedding model, conveniently OOV still recieve embeddings. \n",
    "\n",
    "#### Ratings Model\n",
    "The ratings model is another keras sequential model comprised of three dense layers. For clarification, a dense layer is a layer of neurons that is fully connected to both preceeding and following dense layers if applicable. The first two dense layers contain 256 and 64 neurons respectively, both utilizing the rectified linear unit activation function to introduce non-linearity into the data. The final layer has an output of dimension 1; this dimension is 1 since we are looking to predict a ranking. By using 256 neurons in the first layer, we take our output of a user and news ids embeddings with a combined dimension of 64, and expand it to a higher dimensional space to learn more complex relationships in our data. \n",
    "\n",
    "#### The Call Function\n",
    "The call function uses the sequential models present at initialization on data from the dataset to generate embeddings for the ids present, and then predict the rating given the embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deeper explanation of specific parameter usage in ranking\n",
    "\n",
    "* keras.layers.StringLookup\n",
    "    * Vocabulary : Unique user or news IDs\n",
    "    * Mask Token : With mask token set to none the string lookup layer handles OOV tokens by mapping them to a default index at either 0 or max + 1, currently none however when set to something else the model can better handle OOV tokens.\n",
    "\n",
    "* keras.layers.Embedding\n",
    "    * input_dim : The size of the vocabulary that will be input into the embedding layer.\n",
    "    * output_dim : The size of the embedding vector that will be output.\n",
    "\n",
    "* keras.layers.Dense\n",
    "    * units : The number of neurons to include in the dense layer.\n",
    "    * activation : The activation function to introduce non-linearity into the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval\n",
    "The other main part of a recommender system as mentioned previously in modelling_report, is a retreival step. Different from our previously hard coded retreival steps tensorflow handles retreival in a model itself. \n",
    "\n",
    "### Architecture\n",
    "In the retrieval step the same embedding models from the ranking step are re-used but the rating model is excluded. Where the retrieval model differs however is in its management of the model task. The ranking model uses the tensorflow recommenders ranking task itself with metrics focused on minimizing the loss of the rating prediction function itself. Whereas in the retrieval model, the task itself is a tensorflow recommenders retreival task that uses a tensorflow recommenders factorized top k metric. Overall the retrieval model is much more simple as it just uses embedding models to compute a loss and return recommended movies (go more in depth here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation In The Overall System\n",
    "Ranking model and the later described retrieval model gets placed in a larger model. Modelception! The larger model overall is much smaller where we initialize the ranking model itself, set up a task with our metrics and loss that we minimize and then similar call functions and compute loss functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
