{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Text\n",
    "EMB_DIM=32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "      <th>news_id</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>interaction_type</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U66319</td>\n",
       "      <td>1</td>\n",
       "      <td>N10721</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>entertainment-celebrity</td>\n",
       "      <td>Mike Johnson asks out Keke Palmer after Demi L...</td>\n",
       "      <td>Mike Johnson tried to ask out Keke Palmer in a...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U66319</td>\n",
       "      <td>1</td>\n",
       "      <td>N128129</td>\n",
       "      <td>movies</td>\n",
       "      <td>movies-celebrity</td>\n",
       "      <td>Brie Larson Has the Best Reaction Ever After T...</td>\n",
       "      <td>The 'Captain Marvel' star was left speechless ...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U66319</td>\n",
       "      <td>1</td>\n",
       "      <td>N28406</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>Accused dine-and-dashers in viral video at St....</td>\n",
       "      <td>Five young black men who posted a video of a m...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U66319</td>\n",
       "      <td>1</td>\n",
       "      <td>N118998</td>\n",
       "      <td>news</td>\n",
       "      <td>newsgoodnews</td>\n",
       "      <td>Trooper pulls over to save flag on highway</td>\n",
       "      <td>The trooper is being praised for stopping his ...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U66319</td>\n",
       "      <td>1</td>\n",
       "      <td>N38884</td>\n",
       "      <td>sports</td>\n",
       "      <td>mma</td>\n",
       "      <td>UFC champ Khabib Nurmagomedov seen training in...</td>\n",
       "      <td>Khabib Nurmagomedov doesn't mess around.</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20645888</th>\n",
       "      <td>U491432</td>\n",
       "      <td>0</td>\n",
       "      <td>N87192</td>\n",
       "      <td>finance</td>\n",
       "      <td>finance-companies</td>\n",
       "      <td>Bill Gates tops Jeff Bezos as world's richest ...</td>\n",
       "      <td>This time it's official.</td>\n",
       "      <td>impression</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20645889</th>\n",
       "      <td>U491432</td>\n",
       "      <td>0</td>\n",
       "      <td>N31918</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>Oscar Wilde's stolen ring found by Dutch 'art ...</td>\n",
       "      <td>A golden ring once given as a present by the f...</td>\n",
       "      <td>impression</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20645890</th>\n",
       "      <td>U491432</td>\n",
       "      <td>0</td>\n",
       "      <td>N73556</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_nfl</td>\n",
       "      <td>Report: At least 24 teams expected to attend K...</td>\n",
       "      <td>It looks like the majority of the teams in the...</td>\n",
       "      <td>impression</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20645891</th>\n",
       "      <td>U491432</td>\n",
       "      <td>0</td>\n",
       "      <td>N92223</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestylebuzz</td>\n",
       "      <td>This 10-Year-Old Girl's Demanding Christmas Wi...</td>\n",
       "      <td>A father recently shared his 10-year-old daugh...</td>\n",
       "      <td>impression</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20645892</th>\n",
       "      <td>U491432</td>\n",
       "      <td>0</td>\n",
       "      <td>N114517</td>\n",
       "      <td>sports</td>\n",
       "      <td>baseball_mlb</td>\n",
       "      <td>MLB GM wants Jeff Luhnow 'banned for life' if ...</td>\n",
       "      <td>Another team executive said he wanted to see t...</td>\n",
       "      <td>impression</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20645893 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  time  news_id       category             sub_category  \\\n",
       "0          U66319     1   N10721  entertainment  entertainment-celebrity   \n",
       "1          U66319     1  N128129         movies         movies-celebrity   \n",
       "2          U66319     1   N28406           news                newsworld   \n",
       "3          U66319     1  N118998           news             newsgoodnews   \n",
       "4          U66319     1   N38884         sports                      mma   \n",
       "...           ...   ...      ...            ...                      ...   \n",
       "20645888  U491432     0   N87192        finance        finance-companies   \n",
       "20645889  U491432     0   N31918           news                newsworld   \n",
       "20645890  U491432     0   N73556         sports             football_nfl   \n",
       "20645891  U491432     0   N92223      lifestyle            lifestylebuzz   \n",
       "20645892  U491432     0  N114517         sports             baseball_mlb   \n",
       "\n",
       "                                                      title  \\\n",
       "0         Mike Johnson asks out Keke Palmer after Demi L...   \n",
       "1         Brie Larson Has the Best Reaction Ever After T...   \n",
       "2         Accused dine-and-dashers in viral video at St....   \n",
       "3                Trooper pulls over to save flag on highway   \n",
       "4         UFC champ Khabib Nurmagomedov seen training in...   \n",
       "...                                                     ...   \n",
       "20645888  Bill Gates tops Jeff Bezos as world's richest ...   \n",
       "20645889  Oscar Wilde's stolen ring found by Dutch 'art ...   \n",
       "20645890  Report: At least 24 teams expected to attend K...   \n",
       "20645891  This 10-Year-Old Girl's Demanding Christmas Wi...   \n",
       "20645892  MLB GM wants Jeff Luhnow 'banned for life' if ...   \n",
       "\n",
       "                                                   abstract interaction_type  \\\n",
       "0         Mike Johnson tried to ask out Keke Palmer in a...          history   \n",
       "1         The 'Captain Marvel' star was left speechless ...          history   \n",
       "2         Five young black men who posted a video of a m...          history   \n",
       "3         The trooper is being praised for stopping his ...          history   \n",
       "4                  Khabib Nurmagomedov doesn't mess around.          history   \n",
       "...                                                     ...              ...   \n",
       "20645888                           This time it's official.       impression   \n",
       "20645889  A golden ring once given as a present by the f...       impression   \n",
       "20645890  It looks like the majority of the teams in the...       impression   \n",
       "20645891  A father recently shared his 10-year-old daugh...       impression   \n",
       "20645892  Another team executive said he wanted to see t...       impression   \n",
       "\n",
       "          score  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "...         ...  \n",
       "20645888      0  \n",
       "20645889      0  \n",
       "20645890      0  \n",
       "20645891      0  \n",
       "20645892      0  \n",
       "\n",
       "[20645893 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading in the full dataset\n",
    "dataset=pd.DataFrame()\n",
    "for i in range(4):\n",
    "    df = pd.read_csv(f\"../MIND_large/csv/tensorflow_dataset_chunk{i}.csv\", index_col=0)\n",
    "    dataset = pd.concat([dataset, df])\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_519030/64627017.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['score'] = dataset['score'].astype('float32')\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset[dataset.index < 10000000]\n",
    "dataset['score'] = dataset['score'].astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_519030/2952817448.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# removing the NaN values from the dataset and changing the dataset type into a tensorflow dataset.\n",
    "dataset.dropna(inplace=True)\n",
    "news = pd.read_csv(\"../MIND_large/csv/news.csv\", index_col=0)\n",
    "news.drop(columns=['url', 'title_entities', 'abstract_entities'], inplace=True)\n",
    "news.dropna(inplace=True)\n",
    "tf_ds = tf.data.Dataset.from_tensor_slices(dict(dataset))\n",
    "catalog_ds = tf.data.Dataset.from_tensor_slices(dict(news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping all features to relevant items in the map dataset\n",
    "ratings_ds = tf_ds.map(lambda x : {\n",
    "    'user_id' : x['user_id'],\n",
    "    'news_id' : x['news_id'],\n",
    "    'time' : x['time'],\n",
    "    'category' : x['category'],\n",
    "    'sub_category' : x['sub_category'],\n",
    "    'title' : x['title'],\n",
    "    'abstract' : x['abstract'],\n",
    "    'score' : x['score']\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping all features to relevant items in the map dataset\n",
    "news_ds = catalog_ds.map(lambda x : {\n",
    "    'news_id' : x['news_id'],\n",
    "    'category' : x['category'],\n",
    "    'sub_category' : x['sub_category'],\n",
    "    'title' : x['title'],\n",
    "    'abstract' : x['abstract']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 05:27:30.052511: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-03-21 05:30:03.430969: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-03-21 05:32:27.713398: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-03-21 05:35:01.786033: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-03-21 05:37:17.128894: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Creating lists of all unique user and news ids\n",
    "unique_news_ids = np.unique(np.concatenate(list(news_ds.batch(1000).map(lambda x : x['news_id']))))\n",
    "unique_categories = np.unique(np.concatenate(list(ratings_ds.batch(1000).map(lambda x : x['category']))))\n",
    "unique_subcategories = np.unique(np.concatenate(list(ratings_ds.batch(1000).map(lambda x : x['sub_category']))))\n",
    "\n",
    "\n",
    "\n",
    "unique_user_ids = np.unique(np.concatenate(list(ratings_ds.batch(1000).map(lambda x : x['user_id']))))\n",
    "timestamp_vals = np.unique(np.concatenate(list(ratings_ds.batch(1000).map(lambda x: x['time']))))\n",
    "\n",
    "# Output looks like array([b'U1', b'U100', b'U1000', ..., b'U99993', b'U99994', b'U99998'], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Modelling\n",
    "To finish our implementations of recommender systems we decided to experiment with Tensorflows recommender system library. Tensorflow features robust set of tools to build complex models that we were hoping to experiment more with. Unfortunately due to a bug with the library for the retrieval task, we were unable to implement a complete recommender system. Regardless, we did create a multistage ranking model for a larger recommender system that could rate items for users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking Models\n",
    "The most simple models at our disposal are single ranking or retreival models.\n",
    "\n",
    "### Ranking\n",
    "Given that we have our data in a compatible format, we can initialize a simple ranking model. The ranking model uses the keras model as its super, in doing so we allow ourselves to incorporate our model into the keras ecosystem, define custom behavior and additionally gain access to features present in keras models like specific optimizers. \n",
    "\n",
    "The basic ranking model is comprised of seveeral smaller keras sequential models focused on generating embeddings for features.\n",
    "\n",
    "#### Embedding Models\n",
    "Most embedding models are comprised of 2 layers: string lookup and embedding. The string lookup layer maps items on to unique indices utilizing the unique ID vocabularies generated during the initial processing of data. This index is then passed on to an embedding layer which creates dense vector representations of it using the previously defined embedding dimension. As the model trains these embeddings are updated to improve performance.\n",
    "\n",
    "Two separate embedding models are used to handle vectorizing titles and abstract with similar model definitions. Conveniently, these embedding layers generalize well to unseen data through the use of out of vocabulary tokens. Out of vocabulary tokens, or OOV, are generated when a new user or item is placed in the embedding model, conveniently OOV still recieve embeddings. \n",
    "\n",
    "#### Ratings Model\n",
    "The ratings model is another keras sequential model comprised of dense layers. For clarification, a dense layer is a layer of neurons that is fully connected to both preceeding and following dense layers if applicable. The first dense layers contain a large number of neurons and utilize the rectified linear unit activation function to introduce non-linearity into the data. The final layer has an output of dimension 1; this dimension is 1 since we are looking to predict a ranking.\n",
    "\n",
    "#### The Call Function\n",
    "The call function uses the sequential models present at initialization on data from the dataset to generate embeddings for the ids present, and then predict the rating given the embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(keras.Model):\n",
    "    def __init__(self, embedding_dimension : int = 32):\n",
    "        super().__init__()\n",
    "\n",
    "        # User and article embedding models. \n",
    "        # Define the user ID model.\n",
    "        self.user_embeddings = keras.Sequential([\n",
    "            # Here we exclude the mask token as to better handle OOV items like new users or items.\n",
    "            keras.layers.StringLookup(vocabulary = unique_user_ids),\n",
    "\n",
    "            # Our final layer in the user ID model is an embedding layer which takes the IDs index\n",
    "            # and creates a dense vector representation of it.\n",
    "            keras.layers.Embedding(input_dim = len(unique_user_ids) + 1, output_dim = embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        \n",
    "        self.timestamp_embedding = keras.Sequential([\n",
    "            keras.layers.Embedding(len(timestamp_vals) + 2, 32)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.concat([\n",
    "            self.user_embeddings(inputs['user_id']),\n",
    "            self.timestamp_embedding(inputs['time'])\n",
    "        ], axis=1)\n",
    "\n",
    "class QueryModel(keras.Model):\n",
    "    def __init__(self, layer_sizes):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_model = UserModel()\n",
    "\n",
    "        self.dense_layers = keras.Sequential()\n",
    "\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "        \n",
    "        self.dense_layers.add(keras.layers.Dense(layer_sizes[-1]))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        feature_embedding = self.embedding_model(inputs)\n",
    "        return self.dense_layers(feature_embedding)\n",
    "class NewsModel(keras.Model):\n",
    "\n",
    "    def __init__(self, embedding_dimension : int = 32):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        # Define the news ID model.\n",
    "        self.news_embeddings = keras.Sequential([\n",
    "            # The news ID model is built the same way as the user ID model, just with different vocab and input dimensions.\n",
    "            keras.layers.StringLookup(vocabulary = unique_news_ids),\n",
    "            keras.layers.Embedding(input_dim = len(unique_news_ids) + 1, output_dim = embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        max_title_tokens=1000\n",
    "\n",
    "        self.title_text_embedding = keras.Sequential([\n",
    "            keras.layers.TextVectorization(max_tokens=max_title_tokens),\n",
    "            keras.layers.Embedding(max_title_tokens, embedding_dimension, mask_zero=True),\n",
    "            keras.layers.GlobalAveragePooling1D()\n",
    "        ])\n",
    "\n",
    "        \n",
    "        max_abstract_tokens=5000\n",
    "        self.abstract_text_embedding = keras.Sequential([\n",
    "            keras.layers.TextVectorization(max_tokens=max_abstract_tokens),\n",
    "            keras.layers.Embedding(max_abstract_tokens, embedding_dimension, mask_zero=True),\n",
    "            keras.layers.GlobalAveragePooling1D()\n",
    "        ])\n",
    "\n",
    "        self.category_embeddings = keras.Sequential([\n",
    "            # Here we exclude the mask token as to better handle OOV items like new users or items.\n",
    "            keras.layers.StringLookup(vocabulary = unique_categories),\n",
    "\n",
    "            # Our final layer in the user ID model is an embedding layer which takes the IDs index\n",
    "            # and creates a dense vector representation of it.\n",
    "            keras.layers.Embedding(input_dim = len(unique_categories) + 1, output_dim = embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        self.subcategory_embeddings = keras.Sequential([\n",
    "            # Here we exclude the mask token as to better handle OOV items like new users or items.\n",
    "            keras.layers.StringLookup(vocabulary = unique_subcategories),\n",
    "\n",
    "            # Our final layer in the user ID model is an embedding layer which takes the IDs index\n",
    "            # and creates a dense vector representation of it.\n",
    "            keras.layers.Embedding(input_dim = len(unique_subcategories) + 1, output_dim = embedding_dimension)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.concat([\n",
    "            self.news_embeddings(inputs['news_id']),\n",
    "            # self.title_text_embedding(inputs['title']),\n",
    "            # self.abstract_text_embedding(inputs['abstract']),\n",
    "            self.category_embeddings(inputs['category']),\n",
    "            self.subcategory_embeddings(inputs['sub_category'])\n",
    "        ], axis=1)\n",
    "\n",
    "        # 160\n",
    "\n",
    "\n",
    "class CandidateModel(keras.Model):\n",
    "    \n",
    "    def __init__(self, layer_sizes):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_model = NewsModel()\n",
    "        self.dense_layers = keras.Sequential()\n",
    "\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "        # No activation for the last layer.\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(keras.layers.Dense(layer_size))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # print(inputs)\n",
    "        feature_embedding = self.embedding_model(inputs)\n",
    "        return self.dense_layers(feature_embedding)\n",
    "        \n",
    "\n",
    "class MIND_model(tfrs.models.Model):\n",
    "    \"\"\" \n",
    "    MIND model implementation for Tensorflow modelling with extra features!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rating_weight :float, retrieval_weight : float, layer_sizes = None, embedding_dimension : float = 32): \n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.query_model = QueryModel(layer_sizes)\n",
    "        self.candidate_model = CandidateModel(layer_sizes)\n",
    "\n",
    "        # Define the ratings model. As stated in documentation this can be as complicated as desired.\n",
    "        self.rating_model = keras.Sequential([\n",
    "            # Initialize dense layers of neurons with the rectified linear unit activation function.\n",
    "            keras.layers.Dense(320, activation=\"relu\"),\n",
    "            keras.layers.Dense(256, activation=\"relu\"),\n",
    "            keras.layers.Dense(64, activation=\"relu\"),\n",
    "            keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "        # Now we define tasks\n",
    "        # Set up the task of the recommender system.\n",
    "        self.rating_task = tfrs.tasks.Ranking(\n",
    "            # Select the mean squared error loss function and the rmse for the ranking task and the metrics.\n",
    "            loss = keras.losses.MeanSquaredError(), # Can also swap this out for binary cross entropy, which might be nicer.\n",
    "            metrics = [keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "        # self.retrieval_task = tfrs.tasks.Retrieval(\n",
    "        #     metrics=tfrs.metrics.FactorizedTopK(\n",
    "        #         candidates=news_ds.batch(128).map(self.candidate_model)\n",
    "        #     )\n",
    "        # )\n",
    "\n",
    "        # Define loss weights\n",
    "        self.rating_weight = rating_weight\n",
    "        self.retrieval_weight = retrieval_weight\n",
    "\n",
    "    def call(self, features):\n",
    "        \"\"\"\n",
    "        Allows for the newsRankingModel to be called like a function. As an example, see the following:\n",
    "        newsRankingModel((features[\"user_id\"], features[\"movie_title\"])). In the most simple iteration of this ranking model\n",
    "        only the user and news ids are passed into the inputs argument. \n",
    "\n",
    "        Args:\n",
    "            inputs (tuple) : Inputs is a tuple of features being placed in the call to be extracted with the models \n",
    "            that were defined in the __init__ method.\n",
    "\n",
    "        Returns:\n",
    "            rating (int) : Returns a rating created by passing the elements of `inputs` into the embedding models and\n",
    "            the ratings model.\n",
    "        \"\"\"\n",
    "\n",
    "        # Extract the user and news IDs.\n",
    "        # get stuff from query model\n",
    "        # get stuff from candidate model \n",
    "        # push through ratings        \n",
    "        query_embeddings = self.query_model({\n",
    "            \"user_id\" : features['user_id'], \n",
    "            \"time\" : features['time']\n",
    "        })\n",
    "        candidate_embeddings = self.candidate_model({\n",
    "            \"news_id\": features['news_id'],\n",
    "            \"category\" : features['category'], \n",
    "            \"sub_category\" : features['sub_category'],\n",
    "            \"title\" : features[\"title\"],\n",
    "            'abstract' : features['abstract']\n",
    "        })\n",
    "\n",
    "        return (\n",
    "            query_embeddings,\n",
    "            candidate_embeddings,\n",
    "\n",
    "\n",
    "            # Then apply multi-layered model to concatenation of user and news embeddings.\n",
    "            self.rating_model(\n",
    "                tf.concat([query_embeddings,candidate_embeddings ], axis=1)\n",
    "            )\n",
    "\n",
    "        )\n",
    "    \n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "        ratings = features['score']\n",
    "\n",
    "        # Call the model to get the user and movie embeddings\n",
    "        query_embeddings, candidate_embeddings, rating_predictions = self(features)\n",
    "\n",
    "        # We compute the loss for each task.\n",
    "        rating_loss = self.rating_task(\n",
    "            labels=ratings,\n",
    "            predictions=rating_predictions,\n",
    "        )\n",
    "        # retrieval_loss = self.retrieval_task(query_embeddings, candidate_embeddings)\n",
    "\n",
    "        # And combine them using the loss weights.\n",
    "        return (rating_loss)  # + retrieval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "{'news_id': <tf.Tensor 'data_2:0' shape=(None,) dtype=string>, 'category': <tf.Tensor 'data_3:0' shape=(None,) dtype=string>, 'sub_category': <tf.Tensor 'data_4:0' shape=(None,) dtype=string>, 'title': <tf.Tensor 'data_5:0' shape=(None,) dtype=string>, 'abstract': <tf.Tensor 'data_6:0' shape=(None,) dtype=string>}\n",
      "{'news_id': <tf.Tensor 'data_2:0' shape=(None,) dtype=string>, 'category': <tf.Tensor 'data_3:0' shape=(None,) dtype=string>, 'sub_category': <tf.Tensor 'data_4:0' shape=(None,) dtype=string>, 'title': <tf.Tensor 'data_5:0' shape=(None,) dtype=string>, 'abstract': <tf.Tensor 'data_6:0' shape=(None,) dtype=string>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/layer.py:359: UserWarning: `build()` was called on layer 'mind_model_16', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'news_id': <tf.Tensor 'data_2:0' shape=(None,) dtype=string>, 'category': <tf.Tensor 'data_3:0' shape=(None,) dtype=string>, 'sub_category': <tf.Tensor 'data_4:0' shape=(None,) dtype=string>, 'title': <tf.Tensor 'data_5:0' shape=(None,) dtype=string>, 'abstract': <tf.Tensor 'data_6:0' shape=(None,) dtype=string>}\n",
      "{'news_id': <tf.Tensor 'data_2:0' shape=(None,) dtype=string>, 'category': <tf.Tensor 'data_3:0' shape=(None,) dtype=string>, 'sub_category': <tf.Tensor 'data_4:0' shape=(None,) dtype=string>, 'title': <tf.Tensor 'data_5:0' shape=(None,) dtype=string>, 'abstract': <tf.Tensor 'data_6:0' shape=(None,) dtype=string>}\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0711 - regularization_loss: 0.0000e+00 - total_loss: 0.0712\n",
      "Epoch 2/3\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - loss: 0.0104 - regularization_loss: 0.0000e+00 - total_loss: 0.0104\n",
      "Epoch 3/3\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0080 - regularization_loss: 0.0000e+00 - total_loss: 0.0080\n",
      "{'loss': [0.0, 0.0, 0.0]}\n"
     ]
    }
   ],
   "source": [
    "shuffled = tf_ds.shuffle(10_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(700_000)\n",
    "test = shuffled.skip(700_000).take(300_000)\n",
    "cached_train = train.shuffle(10_000).batch(1000).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "model = MIND_model(layer_sizes=[32], rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "one_layer_history = model.fit(cached_train, validation_data = cached_test, validation_freq=5,  epochs=3)\n",
    "# accuracy = \n",
    "print(one_layer_history.history)\n",
    "# print(f\"Top-100 accuracy: {accuracy:.2f}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'news_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'category': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'sub_category': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>, 'title': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=string>, 'abstract': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>}\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.0096 - regularization_loss: 0.0000e+00 - total_loss: 0.0097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of results\n",
    "Irrespective of our ability to make a complete Tensorflow model we still are able to train a model that can predict item ratings. Overall our results are quite good with our training loss sitting at 0.0080 and our testing loss at 0.0097."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
