{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Documentation\n",
    "Within this document we catalog the different steps that we took with our data from start to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_processing_modules as dpm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"/home/jovyan/work\")\n",
    "import Modelling.matrix_modules as matrix_modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Steps\n",
    "When first downloaded the MIND dataset is contained in .tsv format without column names. Via data_to_csv in data_processing_modules we changed the format to a csv including column names as defined in the MIND Github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes the file specified in the filepath included in the arguments to a csv. \n",
    "dpm.data_to_csv(True, '../MIND_large/tsv/behaviors.tsv')\n",
    "dpm.data_to_csv(False, '../MIND_large/tsv/news.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Compatibility\n",
    "In order to create recommender systems with Tensorflow we needed to update the format of our user behaviors dataset to be compatible. Initially, each row counted as one impression containing a user ID, the users history and all interactions for the given impression; in order to work with Tensorflow we needed each item in btoh history and impressions to be its own row for each interaction. To create the Tensorflow compatible dataset we use `decompose_interactions` which iterates through the behaviors csv expanding out impressions as necessary. Tensorflow recommender systems also supported a time based split for train-test validation meaning that before we created our Tensorflow compatible dataset we binned the timestamps and sorted them with `modify_hourly`. Due to the size of the Tensorflow compatible dataset and our desire to utilize Git Large File Storage, we split the dataset into several chunks so that they are maintainable by Git LFS. The resulting dataset is stored in four chunks at `../MIND_large/csv/tensorflow_dataset_chunk{i}.csv` and is loaded in via the `load_in_tensorflow_full()` function from `matrix_modules`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in necessary data  \n",
    "behaviors = pd.read_csv('../MIND_large/csv/behaviors.csv', index_col=0)\n",
    "news = pd.read_csv('../MIND_large/csv/news.csv', index_col=0)\n",
    "\n",
    "# Binning timestamps.\n",
    "behaviors = dpm.modify_hourly(behaviors)\n",
    "\n",
    "# Sorting the timestamps.\n",
    "behaviors = behaviors.sort_values('time')\n",
    "\n",
    "# Creating the tensorflow dataset.\n",
    "tf_dataset = dpm.decompose_interactions(news, behaviors)\n",
    "\n",
    "# Saving it in chunks.\n",
    "dpm.chunk_tf_dataset(tf_dataset)\n",
    "tf_dataset.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to free up memory.\n",
    "del tf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "In our exploratory data analysis we examined article and category popularity, as well as category popularity at different times of day. Our data visualizations for this exploration required us to modify and extract information from behaviors and news. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Popularity Counts\n",
    "To access popularity counts for both categories and articles we use `create_popularity_csvs`, which iterates over the elements of the behaviors csv keeping track of category popularity and article popularity. The resulting data is stored in `../MIND_large/csv/news_with_popularity.csv` and `../MIND_large/csv/category_with_popularity.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpm.create_popularity_csvs(news, behaviors, small=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing For Temporal Analysis\n",
    "In order to explore how time of day might affect the popularity of categories we counted the per-impression category preference with `create_interaction_counts` which is used to get the popularity of categories for an interaction. The resulting data is stored in `../MIND_large/csv/behaviors_with_individual_counts.csv`. Before data visualization of category popularity given different times, `create_hourly_long` loads in the stored data and uses `modify_hourly` to bin the times before transforming the data into a format useable in the data visualization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpm.create_interaction_counts(behaviors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "Before moving on to clustering we extracted and created features based off of what we learned from our exploratory data analysis. For users we extracted article preferences using the Tensorflow compatible dataset and their median time of interaction. For items we dummy coded their categories, used the previously extracted article popularity and dimension reduced embeddings (maybe on this one).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "      <th>news_id</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>interaction_type</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U66319</td>\n",
       "      <td>1</td>\n",
       "      <td>N10721</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>entertainment-celebrity</td>\n",
       "      <td>Mike Johnson asks out Keke Palmer after Demi L...</td>\n",
       "      <td>Mike Johnson tried to ask out Keke Palmer in a...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U66319</td>\n",
       "      <td>1</td>\n",
       "      <td>N128129</td>\n",
       "      <td>movies</td>\n",
       "      <td>movies-celebrity</td>\n",
       "      <td>Brie Larson Has the Best Reaction Ever After T...</td>\n",
       "      <td>The 'Captain Marvel' star was left speechless ...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U66319</td>\n",
       "      <td>1</td>\n",
       "      <td>N28406</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>Accused dine-and-dashers in viral video at St....</td>\n",
       "      <td>Five young black men who posted a video of a m...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U66319</td>\n",
       "      <td>1</td>\n",
       "      <td>N118998</td>\n",
       "      <td>news</td>\n",
       "      <td>newsgoodnews</td>\n",
       "      <td>Trooper pulls over to save flag on highway</td>\n",
       "      <td>The trooper is being praised for stopping his ...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U66319</td>\n",
       "      <td>1</td>\n",
       "      <td>N38884</td>\n",
       "      <td>sports</td>\n",
       "      <td>mma</td>\n",
       "      <td>UFC champ Khabib Nurmagomedov seen training in...</td>\n",
       "      <td>Khabib Nurmagomedov doesn't mess around.</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id  time  news_id       category             sub_category  \\\n",
       "0  U66319     1   N10721  entertainment  entertainment-celebrity   \n",
       "1  U66319     1  N128129         movies         movies-celebrity   \n",
       "2  U66319     1   N28406           news                newsworld   \n",
       "3  U66319     1  N118998           news             newsgoodnews   \n",
       "4  U66319     1   N38884         sports                      mma   \n",
       "\n",
       "                                               title  \\\n",
       "0  Mike Johnson asks out Keke Palmer after Demi L...   \n",
       "1  Brie Larson Has the Best Reaction Ever After T...   \n",
       "2  Accused dine-and-dashers in viral video at St....   \n",
       "3         Trooper pulls over to save flag on highway   \n",
       "4  UFC champ Khabib Nurmagomedov seen training in...   \n",
       "\n",
       "                                            abstract interaction_type  score  \n",
       "0  Mike Johnson tried to ask out Keke Palmer in a...          history      1  \n",
       "1  The 'Captain Marvel' star was left speechless ...          history      1  \n",
       "2  Five young black men who posted a video of a m...          history      1  \n",
       "3  The trooper is being praised for stopping his ...          history      1  \n",
       "4           Khabib Nurmagomedov doesn't mess around.          history      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating User Features\n",
    "tensorflow_ds = matrix_modules.load_in_tensorflow_full()\n",
    "tensorflow_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>news</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>finance</th>\n",
       "      <th>video</th>\n",
       "      <th>tv</th>\n",
       "      <th>movies</th>\n",
       "      <th>music</th>\n",
       "      <th>autos</th>\n",
       "      <th>health</th>\n",
       "      <th>...</th>\n",
       "      <th>cardio</th>\n",
       "      <th>olympics-videos</th>\n",
       "      <th>hollywood</th>\n",
       "      <th>autosconvertibles</th>\n",
       "      <th>smartliving</th>\n",
       "      <th>soccer_fifa_wwc</th>\n",
       "      <th>strength</th>\n",
       "      <th>newslocalpolitics</th>\n",
       "      <th>games-news</th>\n",
       "      <th>median_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U1</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.236111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U100</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U1000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U10000</td>\n",
       "      <td>0.091954</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.045977</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.114943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U100005</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id      news  entertainment   finance     video        tv    movies  \\\n",
       "0       U1  0.444444       0.236111  0.111111  0.083333  0.097222  0.013889   \n",
       "1     U100  0.162791       0.046512  0.046512  0.046512  0.023256  0.000000   \n",
       "2    U1000  0.444444       0.000000  0.000000  0.000000  0.111111  0.111111   \n",
       "3   U10000  0.091954       0.022989  0.137931  0.034483  0.045977  0.022989   \n",
       "4  U100005  0.354839       0.000000  0.043011  0.010753  0.032258  0.043011   \n",
       "\n",
       "      music     autos    health  ...  cardio  olympics-videos  hollywood  \\\n",
       "0  0.013889  0.000000  0.000000  ...     0.0              0.0        0.0   \n",
       "1  0.046512  0.069767  0.116279  ...     0.0              0.0        0.0   \n",
       "2  0.000000  0.000000  0.000000  ...     0.0              0.0        0.0   \n",
       "3  0.022989  0.011494  0.114943  ...     0.0              0.0        0.0   \n",
       "4  0.000000  0.000000  0.021505  ...     0.0              0.0        0.0   \n",
       "\n",
       "   autosconvertibles  smartliving  soccer_fifa_wwc  strength  \\\n",
       "0                0.0          0.0              0.0       0.0   \n",
       "1                0.0          0.0              0.0       0.0   \n",
       "2                0.0          0.0              0.0       0.0   \n",
       "3                0.0          0.0              0.0       0.0   \n",
       "4                0.0          0.0              0.0       0.0   \n",
       "\n",
       "   newslocalpolitics  games-news  median_time  \n",
       "0                0.0         0.0     0.375000  \n",
       "1                0.0         0.0     0.250000  \n",
       "2                0.0         0.0     0.375000  \n",
       "3                0.0         0.0     0.291667  \n",
       "4                0.0         0.0     0.500000  \n",
       "\n",
       "[5 rows x 270 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features = dpm.create_user_features(tensorflow_ds)\n",
    "user_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>popularity</th>\n",
       "      <th>autos</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>finance</th>\n",
       "      <th>foodanddrink</th>\n",
       "      <th>games</th>\n",
       "      <th>health</th>\n",
       "      <th>...</th>\n",
       "      <th>voices</th>\n",
       "      <th>watch</th>\n",
       "      <th>weatherfullscreenmaps</th>\n",
       "      <th>weathertopstories</th>\n",
       "      <th>weight-loss</th>\n",
       "      <th>weightloss</th>\n",
       "      <th>wellness</th>\n",
       "      <th>wines</th>\n",
       "      <th>wonder</th>\n",
       "      <th>yearinoffbeatgoodnews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N88753</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "      <td>Shop the notebooks, jackets, and more that the...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N23144</td>\n",
       "      <td>50 Worst Habits For Belly Fat</td>\n",
       "      <td>These seemingly harmless habits are holding yo...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N86255</td>\n",
       "      <td>Dispose of unwanted prescription drugs during ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N93187</td>\n",
       "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
       "      <td>Lt. Ivan Molchanets peeked over a parapet of s...</td>\n",
       "      <td>221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N75236</td>\n",
       "      <td>I Was An NBA Wife. Here's How It Affected My M...</td>\n",
       "      <td>I felt like I was a fraud, and being an NBA wi...</td>\n",
       "      <td>1525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 273 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  news_id                                              title  \\\n",
       "0  N88753  The Brands Queen Elizabeth, Prince Charles, an...   \n",
       "1  N23144                      50 Worst Habits For Belly Fat   \n",
       "2  N86255  Dispose of unwanted prescription drugs during ...   \n",
       "3  N93187  The Cost of Trump's Aid Freeze in the Trenches...   \n",
       "4  N75236  I Was An NBA Wife. Here's How It Affected My M...   \n",
       "\n",
       "                                            abstract  popularity  autos  \\\n",
       "0  Shop the notebooks, jackets, and more that the...          10    0.0   \n",
       "1  These seemingly harmless habits are holding yo...           5    0.0   \n",
       "2                                                NaN           8    0.0   \n",
       "3  Lt. Ivan Molchanets peeked over a parapet of s...         221    0.0   \n",
       "4  I felt like I was a fraud, and being an NBA wi...        1525    0.0   \n",
       "\n",
       "   entertainment  finance  foodanddrink  games  health  ...  voices  watch  \\\n",
       "0            0.0      0.0           0.0    0.0     0.0  ...     0.0    0.0   \n",
       "1            0.0      0.0           0.0    0.0     1.0  ...     0.0    0.0   \n",
       "2            0.0      0.0           0.0    0.0     1.0  ...     0.0    0.0   \n",
       "3            0.0      0.0           0.0    0.0     0.0  ...     0.0    0.0   \n",
       "4            0.0      0.0           0.0    0.0     1.0  ...     1.0    0.0   \n",
       "\n",
       "   weatherfullscreenmaps  weathertopstories  weight-loss  weightloss  \\\n",
       "0                    0.0                0.0          0.0         0.0   \n",
       "1                    0.0                0.0          0.0         1.0   \n",
       "2                    0.0                0.0          0.0         0.0   \n",
       "3                    0.0                0.0          0.0         0.0   \n",
       "4                    0.0                0.0          0.0         0.0   \n",
       "\n",
       "   wellness  wines  wonder  yearinoffbeatgoodnews  \n",
       "0       0.0    0.0     0.0                    0.0  \n",
       "1       0.0    0.0     0.0                    0.0  \n",
       "2       0.0    0.0     0.0                    0.0  \n",
       "3       0.0    0.0     0.0                    0.0  \n",
       "4       0.0    0.0     0.0                    0.0  \n",
       "\n",
       "[5 rows x 273 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features = dpm.create_item_features()\n",
    "item_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features.to_csv('../MIND_large/csv/user_features.csv')\n",
    "item_features.to_csv('../MIND_large/csv/item_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "Clustering on both news and users was done to benefit the overall recommender system. To explore parameters for clustering news we vectorized the abstracts and titles, reduced the vectors to two dimensions with UMAP and then applied clustering algorithms like hdbscan and kmeans. Data processing for clustering items was very minimal and completely local, so we don't touch on it much here. With regards to users, previously generated user features were used for clustering experimentation. UMAP reduced embeddings created during this step were stored for quicker availability due to how much longer dimension reduction took for users. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating and storing embeddings\n",
    "Prior to and during model evaluation the embeddings that we evaluated to be the best were stored and accessed when testing different numbers of clusters. We updated the number of clusters by calling either `user_cluster` or `item_cluster`, which takes in our features and applies clustering labels onto them.\n",
    "\n",
    "Importantly, we do not create and evaluate clusters for a train-test split of our data. This is due to the following: clusters weren't used in Tensorflow modelling and clusters were only used in gradient descent and alternating least squares which update and evaluate as matrix factorization occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization Models\n",
    "\n",
    "### Data for Gradient Descent and Alternating Least Squares \n",
    "In our implementations of factorization models like GD and ALS a lot of the previously processed data gets used. Item and user features with appended cluster labels, and the full tensorflow compatible dataset modified to be easy to transform into a ratings matrix $R$. The clustered items, users and complete tensorflow dataset get loaded together with `load_dataset_for_matrix`. Once the data is loaded, hash maps containing indices for use within ALS and a matrix $R$ with either user clustering or item clustering are created with `create_user_cluster_mat` or `create_item_cluster_mat`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recSysEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
