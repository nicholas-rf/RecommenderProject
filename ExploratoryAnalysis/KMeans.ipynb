{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling tensorflow datasets\n",
    "import tensorflow as tf\n",
    "import keras.api._v2.keras as keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = pd.read_csv('../MIND_small/sample_tf_dataset.csv')\n",
    "sample_data.head()\n",
    "sample_data.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time_</th>\n",
       "      <th>news_id</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>interaction_type</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N55189</td>\n",
       "      <td>tv</td>\n",
       "      <td>tvnews</td>\n",
       "      <td>'Wheel Of Fortune' Guest Delivers Hilarious, O...</td>\n",
       "      <td>We'd like to solve the puzzle, Pat: Blair Davi...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N42782</td>\n",
       "      <td>sports</td>\n",
       "      <td>baseball_mlb</td>\n",
       "      <td>Three takeaways from Yankees' ALCS Game 5 vict...</td>\n",
       "      <td>The Yankees kept hope alive thanks to some imp...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N34694</td>\n",
       "      <td>tv</td>\n",
       "      <td>tvnews</td>\n",
       "      <td>Rosie O'Donnell: Barbara Walters Isn't 'Up to ...</td>\n",
       "      <td>Rosie O'Donnell: Barbara Walters Isn't 'Up to ...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N45794</td>\n",
       "      <td>news</td>\n",
       "      <td>newscrime</td>\n",
       "      <td>Four flight attendants were arrested in Miami'...</td>\n",
       "      <td>Four American Airlines flight attendants were ...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N18445</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_ncaa</td>\n",
       "      <td>Michigan sends breakup tweet to Notre Dame as ...</td>\n",
       "      <td>Parting is such sweet sorrow, say the Wolverines.</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id                  time_  ... interaction_type score\n",
       "0  U13740  11/11/2019 9:05:58 AM  ...          history     1\n",
       "1  U13740  11/11/2019 9:05:58 AM  ...          history     1\n",
       "2  U13740  11/11/2019 9:05:58 AM  ...          history     1\n",
       "3  U13740  11/11/2019 9:05:58 AM  ...          history     1\n",
       "4  U13740  11/11/2019 9:05:58 AM  ...          history     1\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec={'user_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'time_': TensorSpec(shape=(), dtype=tf.string, name=None), 'news_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'category': TensorSpec(shape=(), dtype=tf.string, name=None), 'sub_category': TensorSpec(shape=(), dtype=tf.string, name=None), 'title': TensorSpec(shape=(), dtype=tf.string, name=None), 'abstract': TensorSpec(shape=(), dtype=tf.string, name=None), 'interaction_type': TensorSpec(shape=(), dtype=tf.string, name=None), 'score': TensorSpec(shape=(), dtype=tf.int64, name=None)}>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict(sample_data)\n",
    "tf_data_obj = tf.data.Dataset.from_tensor_slices(dict(sample_data))\n",
    "tf_data_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'We\\'d like to solve the puzzle, Pat: Blair Davis\\' loveless marriage? On Monday, \"Wheel of Fortune\" welcomed as a new contestant trucking business owner Blair Davis, who offered a biting introduction for himself. When host Pat Sajak asked the man from Cardiff, California, about his family, Davis plunged into one of the darkest personal summaries the show has likely ever heard. \"I\\'ve been trapped in a loveless marriage for the last 12 years to an...', shape=(), dtype=string)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 19:58:21.509935: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "tf_data_obj = tf.data.Dataset.from_tensor_slices(dict(sample_data))\n",
    "train_ds = tf_data_obj.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "text_ds = train_ds.map(lambda x: x['abstract'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_text():\n",
    "    \"\"\" \n",
    "    Creates embeddings for titles and abstracts for use within clustering.\n",
    "    \"\"\"\n",
    "\n",
    "    vectorize_layer = keras.layers.TextVectorization(standardize='lower_and_strip_punctuation', max_tokens=10000, output_mode='int', output_sequence_length=100)\n",
    "    vectorize_layer.adapt(text_ds)\n",
    "    return vectorize_layer\n",
    "\n",
    "vectorize_layer = handle_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    keras.layers.Embedding(input_dim=10000, output_dim=2)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=z    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/nick/miniforge3/envs/recSysEnv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/nick/miniforge3/envs/recSysEnv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/nick/miniforge3/envs/recSysEnv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/nick/miniforge3/envs/recSysEnv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1152, in train_step\n        self._validate_target_and_loss(y, loss)\n    File \"/Users/nick/miniforge3/envs/recSysEnv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1116, in _validate_target_and_loss\n        raise ValueError(\n\n    ValueError: No loss found. You may have forgotten to provide a `loss` argument in the `compile()` method.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_ds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/recSysEnv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/83/h9nx83394pb5k_0h4zbb4lw00000gn/T/__autograph_generated_file4_d6qvo2.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/nick/miniforge3/envs/recSysEnv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/nick/miniforge3/envs/recSysEnv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/nick/miniforge3/envs/recSysEnv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/nick/miniforge3/envs/recSysEnv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1152, in train_step\n        self._validate_target_and_loss(y, loss)\n    File \"/Users/nick/miniforge3/envs/recSysEnv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1116, in _validate_target_and_loss\n        raise ValueError(\n\n    ValueError: No loss found. You may have forgotten to provide a `loss` argument in the `compile()` method.\n"
     ]
    }
   ],
   "source": [
    "model.fit(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_to_vectorize = [\"This is an example sentence\", \"Another example\"]\n",
    "\n",
    "# Convert texts to embeddings\n",
    "embeddings = embedding_model.predict(texts_to_vectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_column_embeddings(data : pd.DataFrame, feature_name : str, embedding_dimension : int) -> keras.Sequential:\n",
    "    \"\"\" \n",
    "    Creates an embedding model for a feature name.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame) : A dataframe containing the dataset.\n",
    "        feature_name (str) : A column that an embedding model will be created for in order to generate embeddings used in clustering.\n",
    "        embedding_dimension (str) : An embedding dimension for the generated embeddings used for clustering.\n",
    "    \n",
    "    Returns:\n",
    "        embedding_model (keras.Sequential) : A keras sequential model that can be used to create embeddings for a column.\n",
    "    \"\"\"\n",
    "\n",
    "    unique_categories = data[feature_name].nunique()\n",
    "\n",
    "    ## WIll use two separate things depending on if the feature is title or abstract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample_tf_dataset.csv\", index_col='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time_</th>\n",
       "      <th>news_id</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>interaction_type</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>U13740</th>\n",
       "      <td>0</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N55189</td>\n",
       "      <td>tv</td>\n",
       "      <td>tvnews</td>\n",
       "      <td>'Wheel Of Fortune' Guest Delivers Hilarious, O...</td>\n",
       "      <td>We'd like to solve the puzzle, Pat: Blair Davi...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U13740</th>\n",
       "      <td>1</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N42782</td>\n",
       "      <td>sports</td>\n",
       "      <td>baseball_mlb</td>\n",
       "      <td>Three takeaways from Yankees' ALCS Game 5 vict...</td>\n",
       "      <td>The Yankees kept hope alive thanks to some imp...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U13740</th>\n",
       "      <td>2</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N34694</td>\n",
       "      <td>tv</td>\n",
       "      <td>tvnews</td>\n",
       "      <td>Rosie O'Donnell: Barbara Walters Isn't 'Up to ...</td>\n",
       "      <td>Rosie O'Donnell: Barbara Walters Isn't 'Up to ...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U13740</th>\n",
       "      <td>3</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N45794</td>\n",
       "      <td>news</td>\n",
       "      <td>newscrime</td>\n",
       "      <td>Four flight attendants were arrested in Miami'...</td>\n",
       "      <td>Four American Airlines flight attendants were ...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U13740</th>\n",
       "      <td>4</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N18445</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_ncaa</td>\n",
       "      <td>Michigan sends breakup tweet to Notre Dame as ...</td>\n",
       "      <td>Parting is such sweet sorrow, say the Wolverines.</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U19722</th>\n",
       "      <td>2365</td>\n",
       "      <td>11/13/2019 5:53:14 PM</td>\n",
       "      <td>N14029</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestylebuzz</td>\n",
       "      <td>A master suite with an 'open-concept' bathroom...</td>\n",
       "      <td>People took to Twitter to share confusion abou...</td>\n",
       "      <td>impression</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U19722</th>\n",
       "      <td>2366</td>\n",
       "      <td>11/13/2019 5:53:14 PM</td>\n",
       "      <td>N51194</td>\n",
       "      <td>sports</td>\n",
       "      <td>basketball_nba</td>\n",
       "      <td>Gordon Hayward 'Heard, Felt' Hand Break In Col...</td>\n",
       "      <td>Gordon Hayward's broken hand happened so fast ...</td>\n",
       "      <td>impression</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U19722</th>\n",
       "      <td>2367</td>\n",
       "      <td>11/13/2019 5:53:14 PM</td>\n",
       "      <td>N3431</td>\n",
       "      <td>news</td>\n",
       "      <td>newspolitics</td>\n",
       "      <td>Trump Jr's 'Triggered' debuts at No. 1 on NY T...</td>\n",
       "      <td>Donald Trump Jr.'s first book \"Triggered: How ...</td>\n",
       "      <td>impression</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U19722</th>\n",
       "      <td>2368</td>\n",
       "      <td>11/13/2019 5:53:14 PM</td>\n",
       "      <td>N37437</td>\n",
       "      <td>foodanddrink</td>\n",
       "      <td>quickandeasy</td>\n",
       "      <td>How to Make Cornbread Without a Recipe</td>\n",
       "      <td>Cornbread, unlike most breads, is very forgiving.</td>\n",
       "      <td>impression</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U19722</th>\n",
       "      <td>2369</td>\n",
       "      <td>11/13/2019 5:53:14 PM</td>\n",
       "      <td>N63106</td>\n",
       "      <td>news</td>\n",
       "      <td>newsus</td>\n",
       "      <td>Supreme Court Justices Couldn't Stop Interrupt...</td>\n",
       "      <td>The first interruptions came just minutes into...</td>\n",
       "      <td>impression</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2370 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0                  time_ news_id      category  \\\n",
       "user_id                                                            \n",
       "U13740            0  11/11/2019 9:05:58 AM  N55189            tv   \n",
       "U13740            1  11/11/2019 9:05:58 AM  N42782        sports   \n",
       "U13740            2  11/11/2019 9:05:58 AM  N34694            tv   \n",
       "U13740            3  11/11/2019 9:05:58 AM  N45794          news   \n",
       "U13740            4  11/11/2019 9:05:58 AM  N18445        sports   \n",
       "...             ...                    ...     ...           ...   \n",
       "U19722         2365  11/13/2019 5:53:14 PM  N14029     lifestyle   \n",
       "U19722         2366  11/13/2019 5:53:14 PM  N51194        sports   \n",
       "U19722         2367  11/13/2019 5:53:14 PM   N3431          news   \n",
       "U19722         2368  11/13/2019 5:53:14 PM  N37437  foodanddrink   \n",
       "U19722         2369  11/13/2019 5:53:14 PM  N63106          news   \n",
       "\n",
       "           sub_category                                              title  \\\n",
       "user_id                                                                      \n",
       "U13740           tvnews  'Wheel Of Fortune' Guest Delivers Hilarious, O...   \n",
       "U13740     baseball_mlb  Three takeaways from Yankees' ALCS Game 5 vict...   \n",
       "U13740           tvnews  Rosie O'Donnell: Barbara Walters Isn't 'Up to ...   \n",
       "U13740        newscrime  Four flight attendants were arrested in Miami'...   \n",
       "U13740    football_ncaa  Michigan sends breakup tweet to Notre Dame as ...   \n",
       "...                 ...                                                ...   \n",
       "U19722    lifestylebuzz  A master suite with an 'open-concept' bathroom...   \n",
       "U19722   basketball_nba  Gordon Hayward 'Heard, Felt' Hand Break In Col...   \n",
       "U19722     newspolitics  Trump Jr's 'Triggered' debuts at No. 1 on NY T...   \n",
       "U19722     quickandeasy             How to Make Cornbread Without a Recipe   \n",
       "U19722           newsus  Supreme Court Justices Couldn't Stop Interrupt...   \n",
       "\n",
       "                                                  abstract interaction_type  \\\n",
       "user_id                                                                       \n",
       "U13740   We'd like to solve the puzzle, Pat: Blair Davi...          history   \n",
       "U13740   The Yankees kept hope alive thanks to some imp...          history   \n",
       "U13740   Rosie O'Donnell: Barbara Walters Isn't 'Up to ...          history   \n",
       "U13740   Four American Airlines flight attendants were ...          history   \n",
       "U13740   Parting is such sweet sorrow, say the Wolverines.          history   \n",
       "...                                                    ...              ...   \n",
       "U19722   People took to Twitter to share confusion abou...       impression   \n",
       "U19722   Gordon Hayward's broken hand happened so fast ...       impression   \n",
       "U19722   Donald Trump Jr.'s first book \"Triggered: How ...       impression   \n",
       "U19722   Cornbread, unlike most breads, is very forgiving.       impression   \n",
       "U19722   The first interruptions came just minutes into...       impression   \n",
       "\n",
       "         score  \n",
       "user_id         \n",
       "U13740       1  \n",
       "U13740       1  \n",
       "U13740       1  \n",
       "U13740       1  \n",
       "U13740       1  \n",
       "...        ...  \n",
       "U19722       0  \n",
       "U19722       0  \n",
       "U19722       0  \n",
       "U19722       0  \n",
       "U19722       0  \n",
       "\n",
       "[2370 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time_</th>\n",
       "      <th>news_id</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>interaction_type</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>U13740</th>\n",
       "      <td>0</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N55189</td>\n",
       "      <td>tv</td>\n",
       "      <td>tvnews</td>\n",
       "      <td>'Wheel Of Fortune' Guest Delivers Hilarious, O...</td>\n",
       "      <td>We'd like to solve the puzzle, Pat: Blair Davi...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U13740</th>\n",
       "      <td>1</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N42782</td>\n",
       "      <td>sports</td>\n",
       "      <td>baseball_mlb</td>\n",
       "      <td>Three takeaways from Yankees' ALCS Game 5 vict...</td>\n",
       "      <td>The Yankees kept hope alive thanks to some imp...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U13740</th>\n",
       "      <td>2</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N34694</td>\n",
       "      <td>tv</td>\n",
       "      <td>tvnews</td>\n",
       "      <td>Rosie O'Donnell: Barbara Walters Isn't 'Up to ...</td>\n",
       "      <td>Rosie O'Donnell: Barbara Walters Isn't 'Up to ...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U13740</th>\n",
       "      <td>3</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N45794</td>\n",
       "      <td>news</td>\n",
       "      <td>newscrime</td>\n",
       "      <td>Four flight attendants were arrested in Miami'...</td>\n",
       "      <td>Four American Airlines flight attendants were ...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U13740</th>\n",
       "      <td>4</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N18445</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_ncaa</td>\n",
       "      <td>Michigan sends breakup tweet to Notre Dame as ...</td>\n",
       "      <td>Parting is such sweet sorrow, say the Wolverines.</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U19722</th>\n",
       "      <td>2292</td>\n",
       "      <td>11/13/2019 5:53:14 PM</td>\n",
       "      <td>N24150</td>\n",
       "      <td>weather</td>\n",
       "      <td>weathertopstories</td>\n",
       "      <td>Brush fire starts after vehicle goes over High...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U19722</th>\n",
       "      <td>2293</td>\n",
       "      <td>11/13/2019 5:53:14 PM</td>\n",
       "      <td>N6915</td>\n",
       "      <td>foodanddrink</td>\n",
       "      <td>recipes</td>\n",
       "      <td>This Copycat Cracker Barrel Hashbrown Casserol...</td>\n",
       "      <td>If you're craving a slice of Cracker Barrel ha...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U19722</th>\n",
       "      <td>2294</td>\n",
       "      <td>11/13/2019 5:53:14 PM</td>\n",
       "      <td>N20575</td>\n",
       "      <td>tv</td>\n",
       "      <td>tv-celebrity</td>\n",
       "      <td>Ian Ziering's Wife Erin Ludwig Files for Divor...</td>\n",
       "      <td>Ian Ziering's Wife Erin Ludwig Files for Divorce</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U19722</th>\n",
       "      <td>2295</td>\n",
       "      <td>11/13/2019 5:53:14 PM</td>\n",
       "      <td>N6767</td>\n",
       "      <td>news</td>\n",
       "      <td>factcheck</td>\n",
       "      <td>Bogus Warren Quote Ignites Immigration Anger</td>\n",
       "      <td>Immigration comments by Sen. Elizabeth Warren ...</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U19722</th>\n",
       "      <td>2296</td>\n",
       "      <td>11/13/2019 5:53:14 PM</td>\n",
       "      <td>N20602</td>\n",
       "      <td>autos</td>\n",
       "      <td>autosenthusiasts</td>\n",
       "      <td>Someone Just Paid $51,360 For This Perfect 198...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>history</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1050 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0                  time_ news_id      category  \\\n",
       "user_id                                                            \n",
       "U13740            0  11/11/2019 9:05:58 AM  N55189            tv   \n",
       "U13740            1  11/11/2019 9:05:58 AM  N42782        sports   \n",
       "U13740            2  11/11/2019 9:05:58 AM  N34694            tv   \n",
       "U13740            3  11/11/2019 9:05:58 AM  N45794          news   \n",
       "U13740            4  11/11/2019 9:05:58 AM  N18445        sports   \n",
       "...             ...                    ...     ...           ...   \n",
       "U19722         2292  11/13/2019 5:53:14 PM  N24150       weather   \n",
       "U19722         2293  11/13/2019 5:53:14 PM   N6915  foodanddrink   \n",
       "U19722         2294  11/13/2019 5:53:14 PM  N20575            tv   \n",
       "U19722         2295  11/13/2019 5:53:14 PM   N6767          news   \n",
       "U19722         2296  11/13/2019 5:53:14 PM  N20602         autos   \n",
       "\n",
       "              sub_category                                              title  \\\n",
       "user_id                                                                         \n",
       "U13740              tvnews  'Wheel Of Fortune' Guest Delivers Hilarious, O...   \n",
       "U13740        baseball_mlb  Three takeaways from Yankees' ALCS Game 5 vict...   \n",
       "U13740              tvnews  Rosie O'Donnell: Barbara Walters Isn't 'Up to ...   \n",
       "U13740           newscrime  Four flight attendants were arrested in Miami'...   \n",
       "U13740       football_ncaa  Michigan sends breakup tweet to Notre Dame as ...   \n",
       "...                    ...                                                ...   \n",
       "U19722   weathertopstories  Brush fire starts after vehicle goes over High...   \n",
       "U19722             recipes  This Copycat Cracker Barrel Hashbrown Casserol...   \n",
       "U19722        tv-celebrity  Ian Ziering's Wife Erin Ludwig Files for Divor...   \n",
       "U19722           factcheck       Bogus Warren Quote Ignites Immigration Anger   \n",
       "U19722    autosenthusiasts  Someone Just Paid $51,360 For This Perfect 198...   \n",
       "\n",
       "                                                  abstract interaction_type  \\\n",
       "user_id                                                                       \n",
       "U13740   We'd like to solve the puzzle, Pat: Blair Davi...          history   \n",
       "U13740   The Yankees kept hope alive thanks to some imp...          history   \n",
       "U13740   Rosie O'Donnell: Barbara Walters Isn't 'Up to ...          history   \n",
       "U13740   Four American Airlines flight attendants were ...          history   \n",
       "U13740   Parting is such sweet sorrow, say the Wolverines.          history   \n",
       "...                                                    ...              ...   \n",
       "U19722                                                 NaN          history   \n",
       "U19722   If you're craving a slice of Cracker Barrel ha...          history   \n",
       "U19722    Ian Ziering's Wife Erin Ludwig Files for Divorce          history   \n",
       "U19722   Immigration comments by Sen. Elizabeth Warren ...          history   \n",
       "U19722                                                 NaN          history   \n",
       "\n",
       "         score  \n",
       "user_id         \n",
       "U13740       1  \n",
       "U13740       1  \n",
       "U13740       1  \n",
       "U13740       1  \n",
       "U13740       1  \n",
       "...        ...  \n",
       "U19722       1  \n",
       "U19722       1  \n",
       "U19722       1  \n",
       "U19722       1  \n",
       "U19722       1  \n",
       "\n",
       "[1050 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = df[df[\"score\"]==1]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "U10045    [news, foodanddrink, sports, tv, lifestyle, au...\n",
       "U11306    [news, finance, lifestyle, news, lifestyle, ne...\n",
       "U13740    [tv, sports, tv, news, sports, lifestyle, movi...\n",
       "U17841    [lifestyle, health, sports, foodanddrink, food...\n",
       "U19722    [finance, news, news, news, health, foodanddri...\n",
       "U19739    [sports, news, news, news, news, sports, lifes...\n",
       "U29155    [music, sports, music, lifestyle, sports, movi...\n",
       "U34670    [tv, sports, tv, finance, finance, sports, lif...\n",
       "U38627                          [tv, movies, music, tv, tv]\n",
       "U46596                     [sports, sports, sports, sports]\n",
       "U47654    [finance, travel, news, tv, health, lifestyle,...\n",
       "U53231    [news, news, travel, news, travel, finance, ne...\n",
       "U63162    [foodanddrink, news, lifestyle, health, foodan...\n",
       "U70879    [finance, finance, finance, foodanddrink, food...\n",
       "U73700    [lifestyle, lifestyle, news, sports, tv, weath...\n",
       "U79199    [news, news, news, tv, news, news, news, tv, v...\n",
       "U80798    [sports, news, news, news, news, foodanddrink,...\n",
       "U8125                      [autos, travel, weather, health]\n",
       "U8312     [foodanddrink, health, weather, foodanddrink, ...\n",
       "U8355     [news, autos, news, sports, news, sports, musi...\n",
       "U89744    [sports, sports, sports, sports, sports, sport...\n",
       "U91836    [news, news, news, finance, travel, news, news...\n",
       "U92486    [sports, sports, news, news, movies, tv, sport...\n",
       "Name: category, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prof = history.groupby(\"user_id\")['category'].apply(list)\n",
    "user_prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tv', 'sports', 'news', 'lifestyle', 'movies', 'finance', 'travel',\n",
       "       'video', 'weather', 'foodanddrink', 'music', 'health', 'autos',\n",
       "       'entertainment'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for cat in df.category.unique():\n",
    "    user_prof.map(count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
