{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt \n",
    "import umap.plot as uplot\n",
    "import umap.umap_ as umap\n",
    "import hdbscan\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "By clustering our data we minimized our search space for generating recommendations via dimension reduction, and explored possible groupings in our data on more complex featutes. Clustering was accomplished with UMAP and scikit-learn.\n",
    "\n",
    "### Handling slight preprocessing\n",
    "Before exploring clustering results we load in our data with BERT embeddings and apply scikit-learn vectorization methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>0_title</th>\n",
       "      <th>1_title</th>\n",
       "      <th>2_title</th>\n",
       "      <th>3_title</th>\n",
       "      <th>4_title</th>\n",
       "      <th>5_title</th>\n",
       "      <th>6_title</th>\n",
       "      <th>...</th>\n",
       "      <th>758_abstract</th>\n",
       "      <th>759_abstract</th>\n",
       "      <th>760_abstract</th>\n",
       "      <th>761_abstract</th>\n",
       "      <th>762_abstract</th>\n",
       "      <th>763_abstract</th>\n",
       "      <th>764_abstract</th>\n",
       "      <th>765_abstract</th>\n",
       "      <th>766_abstract</th>\n",
       "      <th>767_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N55528</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestyleroyals</td>\n",
       "      <td>-0.760881</td>\n",
       "      <td>0.562061</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>-0.994303</td>\n",
       "      <td>0.949045</td>\n",
       "      <td>0.764554</td>\n",
       "      <td>0.980931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677721</td>\n",
       "      <td>-0.131281</td>\n",
       "      <td>0.538551</td>\n",
       "      <td>-0.444421</td>\n",
       "      <td>-0.435791</td>\n",
       "      <td>-0.197555</td>\n",
       "      <td>-0.140542</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>-0.683746</td>\n",
       "      <td>0.987187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N19639</td>\n",
       "      <td>health</td>\n",
       "      <td>weightloss</td>\n",
       "      <td>-0.787680</td>\n",
       "      <td>0.615142</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>-0.993316</td>\n",
       "      <td>0.964220</td>\n",
       "      <td>0.723472</td>\n",
       "      <td>0.986800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711166</td>\n",
       "      <td>-0.305206</td>\n",
       "      <td>0.766647</td>\n",
       "      <td>-0.613100</td>\n",
       "      <td>-0.373641</td>\n",
       "      <td>-0.565517</td>\n",
       "      <td>-0.063743</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>-0.884546</td>\n",
       "      <td>0.990700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N61837</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>-0.622495</td>\n",
       "      <td>0.460947</td>\n",
       "      <td>0.999873</td>\n",
       "      <td>-0.990779</td>\n",
       "      <td>0.959267</td>\n",
       "      <td>0.900435</td>\n",
       "      <td>0.971245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480411</td>\n",
       "      <td>-0.497116</td>\n",
       "      <td>0.322929</td>\n",
       "      <td>-0.548832</td>\n",
       "      <td>-0.392572</td>\n",
       "      <td>-0.458578</td>\n",
       "      <td>-0.049935</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>-0.713220</td>\n",
       "      <td>0.969965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N53526</td>\n",
       "      <td>health</td>\n",
       "      <td>voices</td>\n",
       "      <td>-0.740854</td>\n",
       "      <td>0.519224</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>-0.995590</td>\n",
       "      <td>0.966713</td>\n",
       "      <td>0.854350</td>\n",
       "      <td>0.986236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703306</td>\n",
       "      <td>-0.143778</td>\n",
       "      <td>0.770481</td>\n",
       "      <td>-0.615078</td>\n",
       "      <td>-0.343000</td>\n",
       "      <td>-0.629248</td>\n",
       "      <td>0.026013</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>-0.805562</td>\n",
       "      <td>0.988447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N38324</td>\n",
       "      <td>health</td>\n",
       "      <td>medical</td>\n",
       "      <td>-0.698660</td>\n",
       "      <td>0.462984</td>\n",
       "      <td>0.999867</td>\n",
       "      <td>-0.990970</td>\n",
       "      <td>0.960319</td>\n",
       "      <td>0.645505</td>\n",
       "      <td>0.976330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761685</td>\n",
       "      <td>-0.117997</td>\n",
       "      <td>0.125520</td>\n",
       "      <td>-0.445764</td>\n",
       "      <td>-0.291769</td>\n",
       "      <td>-0.475241</td>\n",
       "      <td>-0.179736</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>-0.755804</td>\n",
       "      <td>0.974853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1539 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  news_id   category     sub_category   0_title   1_title   2_title   3_title  \\\n",
       "0  N55528  lifestyle  lifestyleroyals -0.760881  0.562061  0.999948 -0.994303   \n",
       "1  N19639     health       weightloss -0.787680  0.615142  0.999966 -0.993316   \n",
       "2  N61837       news        newsworld -0.622495  0.460947  0.999873 -0.990779   \n",
       "3  N53526     health           voices -0.740854  0.519224  0.999932 -0.995590   \n",
       "4  N38324     health          medical -0.698660  0.462984  0.999867 -0.990970   \n",
       "\n",
       "    4_title   5_title   6_title  ...  758_abstract  759_abstract  \\\n",
       "0  0.949045  0.764554  0.980931  ...      0.677721     -0.131281   \n",
       "1  0.964220  0.723472  0.986800  ...      0.711166     -0.305206   \n",
       "2  0.959267  0.900435  0.971245  ...      0.480411     -0.497116   \n",
       "3  0.966713  0.854350  0.986236  ...      0.703306     -0.143778   \n",
       "4  0.960319  0.645505  0.976330  ...      0.761685     -0.117997   \n",
       "\n",
       "   760_abstract  761_abstract  762_abstract  763_abstract  764_abstract  \\\n",
       "0      0.538551     -0.444421     -0.435791     -0.197555     -0.140542   \n",
       "1      0.766647     -0.613100     -0.373641     -0.565517     -0.063743   \n",
       "2      0.322929     -0.548832     -0.392572     -0.458578     -0.049935   \n",
       "3      0.770481     -0.615078     -0.343000     -0.629248      0.026013   \n",
       "4      0.125520     -0.445764     -0.291769     -0.475241     -0.179736   \n",
       "\n",
       "   765_abstract  766_abstract  767_abstract  \n",
       "0      0.999937     -0.683746      0.987187  \n",
       "1      0.999955     -0.884546      0.990700  \n",
       "2      0.999793     -0.713220      0.969965  \n",
       "3      0.999943     -0.805562      0.988447  \n",
       "4      0.999929     -0.755804      0.974853  \n",
       "\n",
       "[5 rows x 1539 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading in the data for tf-idf and bag of words vectorization methods.\n",
    "news_text = pd.read_csv('../MIND_small/csv/news.csv').set_index('news_id').drop(columns=['Unnamed: 0','url','title_entities','abstract_entities'])\n",
    "news_text = news_text[news_text['abstract'].isna() == False]\n",
    "BERT_embeddings = pd.read_csv('../MIND_small/csv/news_BERT_extracted_embeddings.csv', index_col=0).drop(columns='Unnamed: 0')\n",
    "BERT_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sparse matrices of bag of words and tf-idf embeddings.\n",
    "bag_vectorizer = CountVectorizer(stop_words='english')\n",
    "tf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "bow_matrix = bag_vectorizer.fit_transform(news_text['abstract'] + news_text['title'])\n",
    "tf_matrix = tf_vectorizer.fit_transform(news_text['abstract'] + news_text['title'])\n",
    "\n",
    "# If you would like to create a union umap might have to create separate matrices and then concaatenate them onto each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial looks into embeddings\n",
    "To get a good idea of how embeddings might be grouped together for our different embedding methods, we include a small look into the 2 dimensional reductions via umap below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_umap = umap.UMAP(\n",
    "    n_neighbors=30,\n",
    "    min_dist=0.0,\n",
    "    n_components=2,\n",
    "    random_state=42\n",
    ").fit(BERT_embeddings[BERT_embeddings.columns.to_list()[3:]])\n",
    "bow_embeddings = umap.UMAP(\n",
    "    n_neighbors=30,\n",
    "    min_dist=0.0,\n",
    "    n_components=2,\n",
    "    random_state=42\n",
    ").fit(bow_matrix)\n",
    "tf_embeddings = umap.UMAP(\n",
    "    n_neighbors=30,\n",
    "    min_dist=0.0,\n",
    "    n_components=2,\n",
    "    random_state=42\n",
    ").fit(tf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uplot.points(BERT_umap, labels=BERT_embeddings['category'], cmap='vtidis')\n",
    "uplot.points(bow_embeddings, labels=news_text['category'], cmap='vtidis')\n",
    "uplot.points(tf_embeddings, labels=news_text['category'], cmap='vtidis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning\n",
    "To maximize the effectiveness of our clustering in respects to its random and mutual information scores on abstract and title embeddings, we fine tuned specific parameters for the dimension reduction of embeddings with umap and hdbscan clustering. We found that x y and z performed the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_clustering(matrix, n_components=50, metric='euclidean', min_cluster_size=500, n_neighbors=30):\n",
    "    umap_embeddings = umap.UMAP(\n",
    "        n_neighbors=30,\n",
    "        min_dist=0.0,\n",
    "        n_components=n_components,\n",
    "        random_state=42,\n",
    "        metric=metric\n",
    "    ).fit_transform(matrix)\n",
    "    hdbscan_labels = hdbscan.HDBSCAN(min_samples=5, min_cluster_size=500).fit_predict(umap_embeddings)\n",
    "    clustered = (hdbscan_labels >= 0)\n",
    "    print(f\"CLUSTERED: Adjusted random score is: {adjusted_rand_score(news_text['category'][clustered], hdbscan_labels[clustered])},\\n Adjusted mutual info is: {adjusted_mutual_info_score(news_text['category'][clustered], hdbscan_labels[clustered])}\")\n",
    "    print(f\"Adjusted random score is: {adjusted_rand_score(news_text['category'], hdbscan_labels)},\\n Adjusted mutual info is: {adjusted_mutual_info_score(news_text['category'], hdbscan_labels)}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_clustering(matrix, labels, mat_name, n_components=50, metric='euclidean', min_cluster_size=500, n_neighbors=30, min_dist=0.0, min_samples=5, random_state=42, counter=0):\n",
    "    \"\"\"\n",
    "    Tune clustering parameters and evaluate clustering performance.\n",
    "\n",
    "    Parameters:\n",
    "    - matrix: Data matrix to cluster.\n",
    "    - labels: True labels for evaluation.\n",
    "    - n_components: Number of dimensions for UMAP.\n",
    "    - metric: Distance metric for UMAP.\n",
    "    - min_cluster_size: Minimum cluster size for HDBSCAN.\n",
    "    - n_neighbors: Number of neighbors for UMAP.\n",
    "    - min_dist: Minimum distance between points in UMAP space.\n",
    "    - min_samples: Minimum samples for HDBSCAN.\n",
    "    - random_state: Random state for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - Prints evaluation scores.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        umap_embeddings = umap.UMAP(\n",
    "            n_neighbors=n_neighbors,\n",
    "            min_dist=min_dist,\n",
    "            n_components=n_components,\n",
    "            random_state=random_state,\n",
    "            metric=metric,\n",
    "        ).fit_transform(matrix)\n",
    "        \n",
    "        hdbscan_labels = hdbscan.HDBSCAN(\n",
    "            min_samples=min_samples,\n",
    "            min_cluster_size=min_cluster_size\n",
    "        ).fit_predict(umap_embeddings)\n",
    "        \n",
    "        clustered = (hdbscan_labels >= 0)\n",
    "        if clustered.any():\n",
    "            data = pd.DataFrame(data = {'mat' : mat_name, 'n_neighbors' : n_neighbors, 'min_dist' : min_dist, 'n_components' : n_components, 'metric' : metric, 'min_samples' : min_samples, 'min_dist' : min_dist,\n",
    "                                    'clustered_rand' : adjusted_rand_score(labels[clustered], hdbscan_labels[clustered]),\n",
    "                                    'clustered_info' : adjusted_mutual_info_score(labels[clustered], hdbscan_labels[clustered]),\n",
    "                                    'overall_rand' : adjusted_rand_score(labels, hdbscan_labels),\n",
    "                                    'overall_info' : adjusted_mutual_info_score(labels, hdbscan_labels)})\n",
    "\n",
    "            data.to_csv('cluster_tuning.csv', mode='a', index = [counter])\n",
    "\n",
    "        else:\n",
    "            print(\"No clusters formed with the given parameters.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components_range = [10, 50, 100]\n",
    "min_cluster_size_range = [100, 500, 1000]\n",
    "n_neighbors_range = [10, 30, 50]\n",
    "min_dist_range = [0.0, 0.1, 0.5]\n",
    "min_samples_range = [5, 10, 20]\n",
    "\n",
    "# Iterate over each parameter range\n",
    "counter = 0\n",
    "for n_components in n_components_range:\n",
    "    for min_cluster_size in min_cluster_size_range:\n",
    "        for n_neighbors in n_neighbors_range:\n",
    "            for min_dist in min_dist_range:\n",
    "                for min_samples in min_samples_range:\n",
    "                    print(f\"Testing parameters: n_components={n_components}, min_cluster_size={min_cluster_size}, \"\n",
    "                          f\"n_neighbors={n_neighbors}, min_dist={min_dist}, min_samples={min_samples}\")\n",
    "                    \n",
    "                    tune_clustering(tf_matrix, news_text['category'],\n",
    "                                    'tfidf',\n",
    "                                    n_components=n_components, \n",
    "                                    metric='euclidean', \n",
    "                                    min_cluster_size=min_cluster_size, \n",
    "                                    n_neighbors=n_neighbors, \n",
    "                                    min_dist=min_dist, \n",
    "                                    min_samples=min_samples,\n",
    "                                    counter=counter, \n",
    "                                    random_state=42)\n",
    "                    counter += 1\n",
    "                     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = [5, 25, 50]\n",
    "for component in components:\n",
    "    tune_clustering(tf_matrix, n_components=component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_embeddings_norm = umap.UMAP(\n",
    "    n_neighbors=30,\n",
    "    min_dist=0.0,\n",
    "    n_components=50,\n",
    "    random_state=42\n",
    ").fit_transform(tf_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_embeddings = umap.UMAP(\n",
    "    n_neighbors=30,\n",
    "    min_dist=0.0,\n",
    "    n_components=50,\n",
    "    random_state=42\n",
    ").fit_transform(tf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_embeddings_dim_2 = umap.UMAP(\n",
    "    n_neighbors=30,\n",
    "    min_dist=0.0,\n",
    "    n_components=2,\n",
    "    random_state=42\n",
    ").fit_transform(tf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_labels = hdbscan.HDBSCAN(min_samples=5, min_cluster_size=500).fit_predict(umap_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_labels_norm = hdbscan.HDBSCAN(min_samples=5, min_cluster_size=500).fit_predict(umap_embeddings_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_labels_dim_2 = hdbscan.HDBSCAN(min_samples=5, min_cluster_size=500).fit_predict(umap_embeddings_dim_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered = (hdbscan_labels_dim_2 >= 0)\n",
    "plt.scatter(umap_embeddings_dim_2[~clustered, 0],\n",
    "            umap_embeddings_dim_2[~clustered, 1],\n",
    "            color=(0.5, 0.5, 0.5),\n",
    "            s=0.1,\n",
    "            alpha=0.5)\n",
    "plt.scatter(umap_embeddings_dim_2[clustered, 0],\n",
    "            umap_embeddings_dim_2[clustered, 1],\n",
    "            c=hdbscan_labels_dim_2[clustered],\n",
    "            s=0.1,\n",
    "            cmap='Spectral');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hdbscan_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hdbscan_labels_dim_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered = (hdbscan_labels_norm >= 0)\n",
    "print(\n",
    "    adjusted_rand_score(news_text['category'][clustered], hdbscan_labels_norm[clustered]),\n",
    "    adjusted_mutual_info_score(news_text['category'][clustered], hdbscan_labels_norm[clustered])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adjusted_rand_score(news_text['category'], hdbscan_labels_norm), adjusted_mutual_info_score(news_text['category'], hdbscan_labels_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered = (hdbscan_labels >= 0)\n",
    "print(\n",
    "    adjusted_rand_score(news_text['category'][clustered], hdbscan_labels[clustered]),\n",
    "    adjusted_mutual_info_score(news_text['category'][clustered], hdbscan_labels[clustered])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adjusted_rand_score(news_text['category'], hdbscan_labels), adjusted_mutual_info_score(news_text['category'], hdbscan_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered = (hdbscan_labels >= 0)\n",
    "plt.scatter(umap_embeddings[~clustered, 0],\n",
    "            umap_embeddings[~clustered, 1],\n",
    "            color=(0.5, 0.5, 0.5),\n",
    "            s=0.1,\n",
    "            alpha=0.5)\n",
    "plt.scatter(umap_embeddings[clustered, 0],\n",
    "            umap_embeddings[clustered, 1],\n",
    "            c=hdbscan_labels[clustered],\n",
    "            s=0.1,\n",
    "            cmap='Spectral');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now moving onto exploring the embeddings generated by BERT and how they might work\n",
    "embeddings=pd.read_csv('pure_embeddings.csv').set_index('news_id')\n",
    "news = pd.read_csv('MIND_small/csv/news_big_embeddings.csv').drop(columns=['Unnamed: 0', 'abstract_entities', 'title_entities', 'url'])\n",
    "news = news[news['abstract_embeddings'] != '[0]']\n",
    "news = news[news['abstract_embeddings'].isna() == False].set_index('news_id')\n",
    "news.drop(columns = ['abstract_embeddings', 'title_embeddings'], inplace=True)\n",
    "bert_df = pd.concat([news, embeddings], axis=1).drop(columns=['Unnamed: 0.1', 'title', 'abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_umap_embeddings = umap.UMAP(\n",
    "    n_neighbors=30,\n",
    "    min_dist=0.0,\n",
    "    n_components=50,\n",
    "    random_state=42).fit(bert_df[bert_df.columns.to_list()[2:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uplot.points(bert_umap_embeddings, labels=bert_df['category'], cmap='vtidis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recSysEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
